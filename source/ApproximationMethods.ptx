<chapter xmlns:xi="http://www.w3.org/2001/XInclude"  xml:id="CHAPTApproximation">
  <title>Approximation Methods</title>

  <!-- \label{CHAPTApproximation} -->
  <introduction>
    <blockquote>
      <p>
        Although this may seem a paradox, all exact science is
        dominated by the idea of approximation. When a man tells you that he
        knows the exact truth about anything, you are safe in inferring that
        he is an inexact man. Every careful measurement in science is always
        given with the probable error .\ .\ . every observer admits that he is
        likely wrong, and knows about how much wrong he is likely to
        be.
      </p>
      <attribution>
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/">Bertrand
        Russell (1872-1970)</url>
      </attribution>
    </blockquote>


    <blockquote>
      <p>
        I think that it is a relatively good approximation to truth—which is
        much too complicated to allow anything but approximations—that
        mathematical ideas originate in empirics.
      </p>
      <attribution>
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Von_Neumann/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Von_Neumann/">John von
        Neumann (1903-1957)</url>
      </attribution>
    </blockquote>

    <p>
      In a world where you can take your phone out of your pocket, ask
      it for the square root of two (<m>\approx 1.4142135624</m>) or
      the fifth root of seven (<m>\approx 1.47577316159</m>), and
      instantly obtain those numbers accurate to eleven decimal places
      it is difficult to convey the profound importance of having good
      methods of approximation.  There appears to be no need for
      approximations.
    </p>

    <p>
      But stop and think about this for a moment. Both <m>\sqrt{2}</m>
      and <m>\sqrt[5]{7}</m> are irrational numbers so neither can be
      completely represented by a terminating decimal. That is, the
      decimal form of both numbers is infinitely long. So if all we
      have is a value accurate to only eleven decimal places what we
      really have is an approximation, right? It's not even a
      particularly good approximation in the sense that most of the
      information we need to completely specify <m>\sqrt{2}</m> or
      <m>\sqrt[5]{7}</m> in decimal form is missing.
    </p>

    <p>
      The fact is that the modern world could not exist without good
      approximation methods because very little of the information
      necessary to functioning in the modern world can be computed
      precisely. Moreover in those cases where it can be computed
      precisely the exact number is often less useful than the
      approximation. For example, if you are driving to Cincinnati
      your GPS will tell you that you are <m>2</m> hours and <m>25</m>
      minutes away, not <m>145.22434554656546456</m> minutes away,
      even if the latter number is exactly correct.
    </p>

    <p>
      Based on the audio signal your phone receives it constantly
      approximates what signal to send to the speaker for you to
      hear. Because processing an audio signal is such a ubiquitous
      problem, many very sophisticated approximation techniques have
      been developed and they are used all of the time. We don't see
      them because they are usually embedded in software on our many
      electronic devices. Because they are so accurate, we tend not to
      see them as approximations.
    </p>

    <p>
      Every scientific, engineering, or financial computation involves
      approximations because it is almost always impossible to get
      perfect information. We must approximate and we do it all of the
      time. Well, actually most of the time our technology does it for
      us. But our technology is simply the realization of ideas that
      begin with paper, pencil, and thought\aside{Ok, paper and pencil
      are not strictly necessary either because more modern technology
      is rapidly replacing even that. But the need for thought and a
      way to record our thoughts will never change.}. Without these no
      new technology is possible.
    </p>

    <p>
      After the invention of Calculus <mdash/> and especially in the
      twentieth century <mdash/> the number of very good approximation
      techniques ballooned. We will look, very briefly, at two
      pre-Calculus methods of approximation. Then we will consider two
      early approximation methods that came from Calculus, Newton's
      Method and Euler's Method.
    </p>
  </introduction>

  <section xml:id="SECTIONnewtons-method">
    <title>Root Finding: Two  Pre-Calculus Approaches</title>
    <introduction>
      <p>

    </p>
  </introduction>
  
  <subsection xml:id="SUBSECTIONBisectionMethod">
    <title>The Bisection Method</title>
    
    <p>
      The Bisection Method is what nearly everyone would think of
      first when faced with an approximation problem. It sounds very
      complicated when written out in words and symbols, as we're
      about to do, but it is really quite simple. It will help if you
      do the computations along with us, rather than just reading
      them.
      </p>
      <example xml:id="EXAMPLESqrt2-1">
        <p>
          For the sake of having a definite problem to work with
          suppose we want to compute a decimal approximation to
          <m>\sqrt{2}</m>. The Bisection Method works like this: First
          pick two numbers, one less than <m>\sqrt{2}</m>, and one
          greater than <m>\sqrt{2}</m>, In this example we'll choose
          <m>1</m> and <m>2</m>.
        </p>
          
        <p>
          Next, we take the midpoint of the interval <m>[1,2]</m> as
          our first approximation to <m>\sqrt{2}.</m> The midpoint is
          the average of the endpoints so in this example <m>r_1 =
          \frac{1+2}{2}=\frac{3}{2}</m>.  Since <m>\sqrt{2}</m> and
          <m>\frac32</m> are both in the bracketing interval
          <m>[1,2]</m> we see that the distance between
          <m>\sqrt{2}</m> and <m>\frac32</m> is less than <m>1</m>,
          the length of the interval.
        </p>

        <p>
          Now <m>\sqrt{2}</m> must either be in the interval
          <m>[1,3/2]</m> or <m>[3/2,2]</m>. We need to decide which
          one. Since <m>2\lt\frac94=\left(\frac32\right)^2</m> we see
          that <m>\sqrt{2}\lt\frac32</m> so that <m>\sqrt{2}</m> must
          be in the interval <m>[1,3/2]</m>.
        </p>

        <p>
          We take our next approximation to be the midpoint of the
          (smaller) interval <m>[1,3/2]</m>. Thus,
          <m>r_2=\frac{1+\frac32}{2}= \frac54=1.25</m>.  Since <m>
          \left(\frac54\right)^2\le2</m> (confirm this) we have
          <m>\sqrt{2}</m> bracketed by
          <me>
            \frac54\le\sqrt{2} \le\frac32.
          </me>
        </p>
          
        <p>
          This is really the whole idea. If we are approximating a
          number, <m>\alpha</m>, we begin by bracketing <m>\alpha</m>
          between two known numbers, say <m>a</m> and <m>b</m>. We
          take the average of these, <m>r_1=\frac{a+b}{2}</m>, as our
          first approximation of <m>\alpha</m>. We know that
          <m>r_1</m> is within <m>\abs{b-a}</m> (the length of the
          interval <m>[a,b]</m>) of <m>\alpha</m>. If this is
          sufficiently accurate we use <m>r_1</m> as our
          approximation.
        </p>

        <p>
          If not we determine if <m>\alpha</m> is in the first
          half-interval, <m>\left[a, \frac{a+b}{2}\right]</m> or the
          second, <m>\left[\frac{a+b}{2},b\right]</m>, and repeat the
          process, finding a new approximation <m>r_2</m> in an
          interval half the length of the first..
        </p>

        <p>
          The Bisection Method generates a sequence of approximations,
          <m>r_1, r_2, r_3, \ldots</m> of the root we seek. In our
          example we have <m>r_1=\frac32, r_2=\frac54</m> and so
          on. At each step the new approximation is the midpoint of an
          interval whose length is one-half of the length of the
          previous interval. So our approximations can be made as
          close to the target as we would like.
        </p>
      </example>
      <problem xml:id="EXAMPLESqrt2-2">
        <introduction>
          <p>
          </p>
        </introduction>
        <task>
          <statement>
            <p>
              Show that the next two iterations for this example are
              <m>r_3=1.375</m> and <m>r_4=1.4375</m>.
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              The starting interval matters.
              
              <ol>
                <li>
                  <p>
                    For this example take the initial interval to be
                    <m>[1,10]</m> and compute <m>r_1,r_2, r_3</m> and
                    <m>r_4</m>.
                  </p>
                </li>
                <li>
                  <p>
                    Now take the initial interval to be
                    <m>[1/4,3/4]</m> and compute <m>r_1,r_2, r_3</m>
                    and <m>r_4</m>.
                  </p>
                </li>
              </ol>
              If you had to do these computations with paper and
              pencil would you use <m>[1,2]</m>, <m>[1,10]</m>, or
              <m>[1/4,3/4]</m> as your starting interval? Explain
            </p>
          </statement>
        </task>
      </problem>
      <!-- \begin{embeddedproblem-enumerate}  ;;; MULTILEVEL PROBLEM -->
      <!--     \begin{enumerate}[label={  (\alph*)}]  -->
      <!--     \item Show that the next two iterations for this example are -->
      <!--       <m>r_3=1.375</m> and <m>r_4=1.4375</m>. -->
      <!--     \item The starting interval matters. -->
      
      <!-- <ol> -->
      <!--       <li> -->
      <!-- <p> -->
      <!--  For this example take the initial interval to be <m>[1,10]</m> and -->
      <!--         compute <m>r_1,r_2, r_3</m> and <m>r_4</m>. -->
      <!-- </p> -->
      <!-- </li> -->
      <!--       <li> -->
      <!-- <p> -->
      <!--  Now take the initial interval to be <m>[1/4,3/4]</m> and -->
      <!--         compute <m>r_1,r_2, r_3</m> and <m>r_4</m>. -->
      <!-- </p> -->
      <!-- </li> -->
      <!--       </ol> -->

      <!--       If you had to do these computations with paper and pencil -->
      <!--       would you use <m>[1,2]</m>, <m>[1,10]</m>, or <m>[1/4,3/4]</m> as your -->
      <!--       starting interval? Explain -->
      <!--     \end{enumerate} -->
      <!--   \end{embeddedproblem-enumerate} -->

      <p>
        Although we couched it as a purely arithmetic computation,
        when we compute <m>\sqrt{2}</m> it should be clear that we
        found the positive root of the function <m>f(x)=x^2-2.</m> In
        fact the Bisection Method can be used to find the roots of any
        continuous function.
      </p>

      <problem xml:id="PROBLEMbisect-meth">
        <introduction>
          <p>
            Notice that for each of the functions below
            <m>f(4)\gt0</m>. Find the largest positive integer
            <m>r_1</m> such that <m>f(r_1)\lt 0</m>. This says that a
            positive root for the function lies in the interval
            <m>[r_1, 4]</m>. Use the Bisection Method to compute the
            next four approximations, <m>r_2, r_3, r_4</m> and
            <m>r_5</m>.
          </p>
        </introduction>
        <task>
          <statement>
            <p>
              <m>f(x)=x^2-5</m>
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              <m>f(x)=x^2-10</m>
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              <m>f(x)=x^3-7</m>
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              <m>f(x)=x^9-11</m>
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              <m>f(x)=x^5-x^2-8</m>
            </p>
          </statement>
        </task>
        <task>
          <statement>
            <p>
              <m>f(x) = x^3+3x^2-17x+6</m> 
            </p>
          </statement>
        </task>
      </problem>
      <!-- \begin{embeddedproblem} -->
      <!--   <!-\- \label{PROBLEMbisect-meth} -\-> -->
      <!--   Notice that for each of the functions below <m>f(4)\gt0</m>. Find the -->
      <!--   largest positive integer <m>r_1</m> such that <m>f(r_1)\lt 0</m>. This says -->
      <!--   that a positive root for the function lies in the interval -->
      <!--   <m>[r_1, 4]</m>. Use the Bisection Method to compute the next four -->
      <!--   approximations, <m>r_2, r_3, r_4</m> and <m>r_5</m>. -->
      <!--   \begin{enumerate}[label={  (\alph*)}] -->
      <!--     \item <m>f(x)=x^2-5</m> -->
      <!--     \item <m>f(x)=x^2-10</m> -->
      <!--     \item <m>f(x)=x^3-7</m> -->
      <!--     \item <m>f(x)=x^9-11</m> -->
      <!--     \item <m>f(x)=x^5-x^2-8</m> -->
      <!--     \item <m>f(x) = x^3+3x^2-17x+6</m>  -->
      <!--   \end{enumerate} -->
      <!-- \end{embeddedproblem} -->
      <p>
        The Bisection Method is simple, very general, and it always
        works. But, even in ideal circumstances, it is not an efficient
        algorithm. Despite all of our high-speed computational technology
        this is a drawback. We'd like something more efficient.
      </p>

    </subsection>
    <subsection xml:id="SUBSECTIONBabylonianMethod">
      <title>The Babylonian Method for Square Roots</title>

      <p>
        As early as <m>1600</m> BC, the ancient <url
        href="https://mathshistory.st-andrews.ac.uk/HistTopics/Babylonian_mathematics/"
        visual="https://mathshistory.st-andrews.ac.uk/HistTopics/Babylonian_mathematics/">Babylonians</url>
        were using the approximation <m>\sqrt{2}\approx17/12\approx
        1.41667,</m> which is within <m>3/1000</m> of the correct
        value. As with much ancient mathematics we don't really know
        how the Babylonians obtained this kind of accuracy. However
        <url
        href="https://mathshistory.st-andrews.ac.uk/Biographies/Heron/"
        visual="https://mathshistory.st-andrews.ac.uk/Biographies/Heron/">Heron
        of Alexandria</url> (circa <m>10</m> AD - <m>70</m> AD)
        described a method which may be the same as the Babylonian
        method.  The method he described is as follows.
      </p>

      <p>
        As with the Bisection Method we begin by making a guess for
        <m>\sqrt{2}.</m> We'll label our first guess <m>r_1</m> as
        before.  Just as with the Bisection Method we'd like to have
        <m>\sqrt{2}</m> bracketed between two numbers. <xref
        ref="DRILLBabylonFirstGuess">Drill\</xref> shows how to do
        that.
      </p>

      <exercise xml:id="DRILLBabylonFirstGuess">
        <statement>
          <p>
            Show that if <m>r_1 \lt \sqrt{2}</m> then <m>\frac{2}{r_1}
            \gt \sqrt{2}</m>, and that if <m>r_1 \gt \sqrt{2}</m> then
            <m>\frac{2}{r_1} \lt \sqrt{2}</m>.
          </p>
        </statement>
      </exercise>

      <p>
        Here we will let <m>r_1=1</m> be our guess and notice that
        <m>r_1\lt\sqrt{2}</m>. In light of <xref
        ref="DRILLBabylonFirstGuess"></xref> we see that
        <m>\frac{2}{r_1}=\frac{2}{1}\gt\sqrt{2}</m> so, as before, we
        have <m>\sqrt{2}</m> somewhere in the interval
        <m>[1,2]</m>. Also as before, we take the average of these two
        numbers to get our second approximation,
        <me>
          r_2 = \frac12\left(r_1+\frac{2}{r_1}\right) =
          \frac12\left(1+\frac21\right) = \frac32.
        </me>
      </p>

      <p>
        In the Bisection Method we needed to determine if this was
        less than or greater than <m>\sqrt{2}</m>. In the Babylonian
        algorithm it doesn't matter for <m>\sqrt{2}</m> will always be
        between <m>r_2</m> and <m>\frac{2}{r_2}</m> (by <xref
        ref="DRILLBabylonFirstGuess"></xref>). We average these
        together to get our third approximation,
        <me>
          r_3=\frac12\left(r_2+\frac{2}{r_2}\right)=\frac12\left(\frac32+\frac{2}{\frac32}\right)=\frac12\left(\frac32+\frac43\right)=\frac{17}{12}.
        </me>    
      </p>

      <p>
        This is the Babylonian approximation which we mentioned
        earlier is within <m>1/1000</m> of the correct value.
      </p>

      <p>
        It's pretty remarkable that we can get such a good
        approximation of <m>\sqrt{2}</m> with so little arithmetic.
        If we were to apply the algorithm again, we would get an even
        closer approximation.
      </p>

      <exercise xml:id="EXAMPLESqrt2-3">
        <statement>
          <p>
            Compute <m>r_4</m>. You should get an approximation within
            <m>3/1000000</m> of the correct value. Do you?
          </p>
        </statement>
      </exercise>

      <problem xml:id="PROBLEMBabylonianMethod">
        <introduction>
          <p>
          </p>
        </introduction>
        <task>
          <statement>
            <p>
              Write down the Babylonian method, as described by Heron, as an
              algorithm.
            </p>
          </statement>
       </task>
       <task>
         <statement>
           <p>
             Choose and initial guess and then use your algorithm to
             compute an approximation of <m>\sqrt{5}</m>.
           </p>
         </statement>
       </task>
       <task>
         <statement>
           <p>
             Approximate <m>\sqrt{10}</m> using the Babylonian method.
           </p>
         </statement>
       </task>
    </problem>
<!-- \begin{embeddedproblem-enumerate} -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Write down the Babylonian method, as described by Heron, as an -->
<!--     algorithm. -->
<!--   \item Choose and initial guess and then use your algorithm to -->
<!--     compute an approximation of <m>\sqrt{5}</m>. -->
<!--   \item  Approximate <m>\sqrt{10}</m> using the Babylonian method. -->
<!--       \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->

<problem xml:id="PROBLEMBabylMeth4">
  <introduction>
    <p></p>
</introduction>
<task>
  <statement>
    <p>
      Suppose you wanted to use the Babylonian algorithm to
      approximate (Yes, we know this is <m>2</m>. Work with us
      here.) <m>\sqrt{4}</m> and started with an initial guess of
      <m>2</m>.  What would happen?
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      What would happen in the general case for <m>\sqrt{N^2}</m> if you
      ever got <m>r_n=N</m>?
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem-enumerate} -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Suppose you wanted to use the Babylonian algorithm to -->
<!--     approximate\aside{Yes, we know this is <m>2</m>. Work with us -->
<!--       here.} <m>\sqrt{4}</m> and started with an initial guess of <m>2</m>.  What -->
<!--     would happen?  -->
<!--   \item What would happen in the general case for <m>\sqrt{N^2}</m> if you -->
<!--     ever got <m>r_n=N</m>? -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->

<p>
  Again, no one knows how the Babylonians discovered this
  algorithm\aside{Not even Heron knew; look at the dates involved.}, but
  some interesting questions arise from it: What about <m>\sqrt[3]{2}?</m> Is
  there some similar algorithm that approximates cube roots? Fourth
  roots? Fifth? Two hundred and eighty-seventh roots?
</p>
<p>

  Of course the answer to all of these questions is yes, otherwise we
  wouldn't have asked. But  to see why we'll have to step away
  from the Babylonians for a bit.
</p>



</subsection>
</section>


<section xml:id="SECTIONnewtons-method-1">
<title>Newton's Method</title>

<introduction>
  <p>

    When Calculus came along, Newton
    realized  that his new invention could be used to approximate solutions
    to equations by a particularly simple method now called, reasonably
    enough, Newton's Method\aside{This is sometimes also called the Newton-Raphson
    Method. <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Raphson/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Raphson/">Joseph
    Raphson</url> (<m>1668-1712</m>) was a younger contemporary of Newton who
    apparently invented this method independently.}.
</p>
<p>

  We will use Newton's Method to <q>re-invent</q> the Babylonian square
  root algorithm and, more importantly, to generalize it.  Here's the
essential idea: We know how to find the root of a <term>linear</term>
equation like <m>ax+b=0</m>.  We want to use this knowledge to approximate
the root of a nonlinear equation.  As with the rest of Calculus this
means that the <term>Principle of Local Linearity</term> is the postulate
underlying Newton's Method.
</p>
<p>

  For our purposes this means that we can approximate the
  coordinates of points on a curve with the coordinates of points on the
  line tangent to the curve when the the point of tangency is
  nearby. Moreover this approximation gets better as we get closer to
  the point of tangency.
</p>
<p>


  Before we return the the square root problem we consider the problem
  of approximation more broadly.
</p>

<example xml:id="EXAMPLEnewtons-method1">

  <figure>
    <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/nm1.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[10]{r}{2.1in} -->
<!--     \captionsetup{labelformat=empty} -->
<!--     \vskip-12mm  -->
<!--         \includegraphics*[height=1.5in,width=2.1in]{../Figures/nm1} -->
<!--     \label{fig:nm1} -->
<!--   \end{wrapfigure} -->

<p>

Most mathematical software will accept the equation <m>x^3-3x^2=5x+6</m>
as input and give back the approximate solution <m>x=4.433</m> at the
click of a button.  As a result it is easy to get the impression
that this is a a simple problem.  But, imagine yourself back in the
late <m>17</m>th century for a moment. The only computation technology
available is paper and pencil. How would you solve this problem?
How would you even generate an approximate solution?
</p>
<p>

  One possibility is to graph <m>y=x^3-3x^2</m> and <m>y=5x+6</m> on the same
  set of axes and look for the value of <m>x</m> where the two graphs
  intersect as in the figure above at the right. This seems like a
  good idea until we actually try it.  Immediately we realize that
  accurately graphing even simple equations would have been an almost
  insurmountable task in those days. We clearly used modern technology
  to draw the graph pictured. Drawing it by hand accurately enough to
  glean useful information from it would have been virtually
  impossible.
</p>
<p>

  Here's another idea. If we rearrange the equation just a little we
  get
  <me>
    x^3-3x^2-(5x+6)=0.\label{eq:NewtonMethod1}
</me>
Now define <m>f(x)</m> to be the expression on the left of
<xref ref="EQNewtonMethod1">Equation~</xref>): <m>f(x) = x^3-3x^2-(5x+6)</m>. The graph
of this function, seen at the left, will cross the <m>x</m>-axis (that is
<m>f(x)=0</m>) at the same <m>x</m> coordinate where the equation
<m>x^3-3x^2 = 5x+6</m> is satisfied. This simple observation allows us to
think of the problem in a slightly different way: We are looking for
the <m>x</m> value which is a root of the function <m>f(x)</m>.
</p>

<figure>
  <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/nm5.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[]{l}{2in} -->
<!--     \vskip-4mm  -->
<!--     \captionsetup{labelformat=empty} -->
<!--     \centerline{\includegraphics*[height=1.8in,width=2in]{../Figures/nm5}} -->
<!--     \label{fig:nm5} -->
<!--   \end{wrapfigure} -->

<p>

  You wouldn't think such a simple change would help. But it does.
  Now, instead of looking for both the <m>x</m> and <m>y</m> coordinates of an
  intersection point we need only  search for the  value of <m>x</m> where the
  graph of the function <m>f(x)=x^3-3x^2-(5x+6) </m> crosses the <m>x-</m>axis.
  This gives us just a little more information because we know that the
  <m>y</m> coordinate is zero if a point is on the <m>x</m>-axis.
</p>

<p>
  As before we will need an initial guess to get started. Since the root
  seems to be close to <m>4</m> we'll use <m>r_1=4</m> as our first approximation.
  Now  find and sketch the line tangent to
  <m>f(x)</m> at <m>r_1=4</m> as seen in the sketch at the left (in red). If our first
  guess is close to the actual root the Principle of Local Linearity
  guarantees that the tangent line will cross the <m>x</m>-axis very near to
  the actual root.  So the value of <m>x</m>, whatever it is, where the
  tangent line crosses seems like it would be a pretty good second
  approximation <m>r_2</m>, of the root of <m>f(x) = x^3-3x^2-(5x+6)</m>. If we zoom
  in on this part of our graph, as in the figure, this is easy to see.
</p>
<p>

  Apparently all we have to do now is determine the slope of the line
  tangent to the graph at <m>r_1= 4</m>, then find the equation of the line
  and its <m>x</m>-intercept.
</p>
</example>

<exercise  xml:id="DRILLNewtonMethod2">
  <introduction>
    <p>
      <!-- \vskip-6mm  -->
      <!-- \label{drill:NewtonMethod2} -->
</p>
</introduction>
<task>
  <statement>
    <p>
      Show that in this example an equation of the line tangent to
      <m>f(x)</m> at <m>r_1=4</m> is
<me> y+10=19(x-4).  </me>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Our second approximation (<m>r_2</m>) to the root we seek will be
      the <m>x</m> coordinate of the point where the line in part (a)
crosses the <m>x-</m>axis. That is, where <m>y=0.</m>

Set <m>y=0</m> and show that the line in part (a) crosses the
<m>x-</m>axis at <m>r_2= \frac{10}{19}+4\approx 4.526</m>.
</p>
</statement>
</task>
</exercise>
<!-- begin{ProficiencyDrill} -->
<!--   \vskip-6mm  -->
<!--   \label{drill:NewtonMethod2} -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--         \item Show that in this example an equation of the line tangent to -->
<!--     <m>f(x)</m> at <m>r_1=4</m> is -->
<!--     <me> -->
<!--     y+10=19(x-4). -->
<!--     </me> -->
<!--   \item Our second approximation (<m>r_2</m>) to the root we seek will be the -->
<!--     <m>x</m> coordinate of the point where the line in part (a) crosses the -->
<!--     <m>x-</m>axis. That is, where <m>y=0.</m> -->

<!--     Set <m>y=0</m> and show that the line in part (a) crosses the <m>x-</m>axis at -->
<!--     <m>r_2= \frac{10}{19}+4\approx 4.526</m>. -->
<!--         \end{enumerate} -->
<!-- \end{ProficiencyDrill} -->
<p>

  The approximation we found in <xref ref="DRILLNewtonMethod2"></xref> is
  better than our original guess of <m>r_1=4</m>, but it is still not great
  since <m>f(4.526) \approx 2.6</m>, whereas if we'd found the actual root,
<m>r</m>, we'd have <m>f(r)=0.</m>
</p>
<p>

  But we don't have to stop there, and the pattern should be clear. If
  we wanted a more accurate approximation we could use <m>r_2</m> to generate
  an <m>r_3,</m> and so on. We stop when our approximation is accurate enough
  for our purposes.
</p>


<problem xml:id="PROBLEMTanToCubic">
  <introduction>
<image source="images/NewtonsMethod4.png" width="50%"/>
</introduction>
<task>
  <statement>
    <p>
      Find the equation of the line tangent to the function
      <m>f(x)=x^3-3x^2-(5x+6)</m> at <m>r_2=4.526</m> and use this to show that
      our third approximation to the root of <m>f(x)</m> is
      <m>r_3\approx 4.436</m>.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Repeat part (a) using the line tangent at <m>r_3=4.436</m> to
      obtain the next approximation <m>r_4</m>, but this time round it off to
      <m>6</m> decimal places.
      \comment{You will need <m>6</m> digits for  part (d).}
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      If you've done it correctly, you will notice that <m> r_2\gt r_3\gt r_4</m>.
      Does this surprise to you? Explain.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Use your favorite computational software to find an
approximation to the root of <m>f(x)=x^3-x^2-(5x+6)</m> to <m>6</m>
decimal places.
Compare your <m>r_4</m> to this approximation. How close
did you come?
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem-enumerate}  -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Find the equation of the line tangent to the function -->
<!--     <m>f(x)=x^3-3x^2-(5x+6)</m> at <m>r_2=4.526</m> and use this to show that -->
<!--     our third approximation to the root of <m>f(x)</m> is -->
<!--     <m>r_3\approx 4.436</m>. -->
<!--   \item Repeat part (a) using the line tangent at <m>r_3=4.436</m> to -->
<!--     obtain the next approximation <m>r_4</m>, but this time round it off to -->
<!--     <m>6</m> decimal places. -->
<!--     \comment{You will need <m>6</m> digits for  part (d).} -->
<!--   \item If you've done it correctly, you will notice that <m> r_2\gt r_3\gt r_4</m>. -->
<!--     Does this surprise to you? Explain. -->
<!--   \item Use your favorite computational software to find an -->
<!--     approximation to the root of <m>f(x)=x^3-x^2-(5x+6)</m> to <m>6</m> -->
<!--     decimal places. Compare your <m>r_4</m> to this approximation. How close -->
<!--     did you come? -->
<!--                                 \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->






<!-- <figure> -->
<!--   <caption> -->
<!-- <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url> -->
<!-- </caption> -->
<!-- <image source="images/NewtonsMethod4.png" width="50%"/> -->
<!-- </figure> -->
<!-- \begin{wrapfigure}[]{r}{3.5in} -->
<!--   \captionsetup{labelformat=empty} -->
<!--       \centerline{\includegraphics*[height=2.2in,width=3.5in]{../Figures/NewtonsMethod4}} -->
<!--   \label{fig:NewtonsMethod2} -->
<!-- \end{wrapfigure} -->

<p>

  When computing approximations our goal is to compute good
  approximations efficiently, not to do a lot of arithmetic. We'd
  actually like to avoid doing arithmetic as much as possible. So it will
  be worth the effort needed to organize our computations as much as we
  can. Fortunately this is not hard to do.
</p>
<p>

  In  the diagram at the right we see the graph of a generic function
  <m>y=y(x)</m>. Suppose we have used Newton's Method repeatedly and found
  the <m>n</m>th approximation, <m>r_n</m>, of the the root (the <m>n</m>th iterate).
  We'd like to find a formula to compute the next
  iterate, <m>r_{n+1}</m>, without having to draw the sketch and solve a new
  equation.
  <xref ref="PROBLEMNewtonsMethod3">Problem~\</xref> leads you through this process.
</p>


<problem xml:id="PROBLEMNewtonsMethod3">
  <introduction>
    <p>
</p>
</introduction>
<task>
  <statement>
    <p>
      Find the equation of the line tangent to the curve <m>y=y(x)</m> at
      the point <m>(r_n, y(r_n))</m>. Show that it can be written in the form
      <me>
        y=y(r_n)+\dfdxat{y}{x}{r_n}(x-r_n).
</me>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Use your answer to part (a) to show that
      <me>

        r_{n+1}=r_n-\frac{y(r_n)}{y^\prime(r_n)}.\label{eq:NewtonMethod}
        
</me>
<xref ref="EQNewtonMethod">Equation</xref> is the general formula for Newton's Method.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      If we get lucky and <m>r_n</m> is the actual root of the function
      <m>y(x)</m> (not just an approximation). Explain  what happens at the next
      iteration if <m>r_n</m> is not the root.

</p>
</statement>
</task>
</problem>



<p>

  In <xref ref="SUBSECDerivative"></xref> we introduced Lagrange's `prime'
  notation for the derivative: If <m>y=y(x)</m> then
  <m>\dfdx{y}{x}=y^\prime(x)</m>. We also commented that when the
  differential form becomes cumbersome we would switch to Lagrange's
  notation.  Such a time has come.
</p>
<p>

  Lagrange had conceptual reasons for this change in notation, but we
  just want to streamline our notation a bit.  Since we will be looking at
  tangent lines to curves it will be easier on the eyes to write
  <men  xml:id="EQUATIONLineWPrime">
    y=y(r_n)+y^\prime(r_n)(x-r_n)
</men>
than
<men  xml:id="EQUATIONLineWDiff">
  y=y(r_n)+\eval{\dfdx{y}{x}}{x}{r_n}(x-r_n).
</men>
We still prefer differential notation seen in <xref ref="EQUATIONLineWDiff">Equation</xref> for most purposes so in
the next chapter we will switch back to it, but the prime notation used in <xref ref="EQUATIONLineWPrime">Equation</xref>
is a little smoother for our present purpose.
</p>


<p>
  We summarize the foregoing succinctly as follows:
</p>

<algorithm>
<title>Newton<rsq/>s Method</title>
<p>
  Given a differentiable function, <m>y=y(x),</m> with a root at
  <m>x=r</m> we can approximate <m>r</m> as follows.
  <ol>
    <li>
      <p>
Choose <m>r_1.</m>
</p>
</li>
<li>
  <p>
    For <m>n=2, 3, 4, \ldots</m> compute <me>
    r_{n+1}=r_n-\frac{y(r_n)}{y^\prime(r_n)} </me> until the
    desired level of accuracy is obtained.
</p>
</li>
</ol>
</p>
</algorithm>

<p>
  One reason for writing down Newton's Method in this compact form is that
  this makes it easier to program into a computer.
</p>

<p>
  As intimidating as the general formula might first appear, remember
  that ultimately we are simply constructing and solving a single linear
  equation.  This is clear from the derivation of the formula. The
  apparent complexity appears only because we have arranged to construct
  and solve the equation in a single step.
</p>
<p>

  Newton's Method works because the property of being the root of a
  function is a local, not a global property.  If our approximation,
  <m>r_n,</m> is quite close to the root we seek then we can safely
  assume\aside{Most of the time. See the discussion below.}  that the curve and its tangent line
  are practically the same. This is, of course, the
  <term>Principle of Local Linearity</term> again.
</p>




<p>
  At the end of  step <m>2</m>  we used the phrase <q>until the desired
  level of accuracy is obtained.</q>  Clearly we are being cagey.  How
  can we tell when we have an estimate which is accurate to any
  level of precision, let alone the desired level?  This is a harder
  question than it probably appears to be. For that reason we will not
  be looking into it very deeply. For our purposes it will be good
  enough to assume that if the first four digits to the right of the
  decimal have not changed from one iteration to the next then our
  estimate is accurate to four decimal places.
</p>
<exercise xml:id="EXERCISESqrt2InitGuess">
  <statement>
    <p>
      Obviously, <m>f(x) = x-\sqrt{2}</m> has a root at <m>x=\sqrt{2}.</m> But if we
      want to compute <m>\sqrt{2}</m> this is not a good choice of function to
      apply Newton's Method to. Explain why not. What would be a good
      choice for <m>f(x)</m> if we wish to approximate <m>\sqrt{2}</m>?
</p>
</statement>
</exercise>

<problem xml:id="PROBLEMNewtMethCreateFunction">
  <introduction>
    <p>
      Create a function which has a root at each of the following numbers
      and use your function to compute each to <m>5</m> decimals using Newton's
      Method.
</p>
</introduction>
<task>
  <statement>
    <p>
<m>\sqrt[5]{7}</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>\sqrt[3]{5} </m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>6^{2/3}</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>\sqrt{27}</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>\sqrt[7]{2}</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>\pi</m>
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem-1line}  -->
<!--   <!-\- \label{PROBLEMNewtMethCreateFunction} -\-> -->
<!--   Create a function which has a root at each of the following numbers -->
<!--   and use your function to compute each to <m>5</m> decimals using Newton's -->
<!--   Method. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--     \item <m>\sqrt[5]{7}</m> -->
<!--     \item <m>\sqrt[3]{5} </m> -->
<!--     \item <m>6^{2/3}</m> -->
<!--     \item  <m>\sqrt{27}</m>  -->
<!--     \item  <m>\sqrt[7]{2}</m> -->
<!--     \item <m>\pi</m> -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem-1line} -->

<problem xml:id="PROBLEMNewton-meth">
  <introduction>
    <p>
      Start with <m>r_1=4</m> and use Newton's Method to compute the next four
      approximations (<m>r_2</m>, <m>r_3</m>, <m>r_4</m>, and <m>r_5</m>) of the roots of each
      of the following functions. Compare these with your results in
      <xref ref="PROBbisect-meth">Problem~\#</xref>. Which algorithm seems to be more
      accurate after four iterations?
</p>
</introduction>
<task>
  <statement>
    <p>
<m>f(x)=x^2-5</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x)=x^2-10</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x)=x^3-7</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x)=x^9-11</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x)=x^5-x^2-8</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x) = x^3+3x^2-17x+6</m>
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   <!-\- \label{PROBLEMNewton-meth} -\-> -->
<!--   Start with <m>r_1=4</m> and use Newton's Method to compute the next four -->
<!--   approximations (<m>r_2</m>, <m>r_3</m>, <m>r_4</m>, and <m>r_5</m>) of the roots of each -->
<!--   of the following functions. Compare these with your results in -->
<!--   <xref ref="PROBbisect-meth">Problem~\#</xref>. Which algorithm seems to be more -->
<!--   accurate after four iterations? -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--     \item <m>f(x)=x^2-5</m> -->
<!--     \item <m>f(x)=x^2-10</m> -->
<!--     \item <m>f(x)=x^3-7</m> -->
<!--     \item <m>f(x)=x^9-11</m> -->
<!--     \item <m>f(x)=x^5-x^2-8</m> -->
<!--     \item <m>f(x) = x^3+3x^2-17x+6</m>  -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->



<problem xml:id="PROBLEMNewton-meth2">
  <introduction>
    <p>
      Use Newton's Method to approximate the root of each of the following
      functions to at least four decimal places on the interval given.
</p>
</introduction>
<task>
  <statement>
    <p>
<m>f(x) = \frac{x^2-x+2}{x^2(x-1)}-3</m> on <m>[0,2]</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x) = x^\frac13+\cos(2x) -1/2</m> on <m>[0,3/2]</m>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
<m>f(x) = (x-1/2)\cos\left(x^2+2x\right)+1</m> on <m>[-2,0]</m>
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   <!-\- \label{PROBLEMNewton-meth2} -\-> -->
<!--   Use Newton's Method to approximate the root of each of the following -->
<!--   functions to at least four decimal places on the interval given. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--       \item <m>f(x) = \frac{x^2-x+2}{x^2(x-1)}-3</m> on <m>[0,2]</m>   -->
<!--       \item <m>f(x) = x^\frac13+\cos(2x) -1/2</m> on <m>[0,3/2]</m> -->
<!--   \item <m>f(x) = (x-1/2)\cos\left(x^2+2x\right)+1</m> on <m>[-2,0]</m>   -->
<!--       \end{enumerate} -->
<!-- \end{embeddedproblem} -->


<problem xml:id="PROBLEMXCosx">
  <statement>
    <figure>
      <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/NewtonsMethod3.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[]{r}{3.6in} -->
<!--     \vskip-6mm  -->
<!--     \captionsetup{labelformat=empty} -->
<!--         \centerline{\includegraphics*[height=1.8in,width=2.8in]{../Figures/NewtonsMethod3}} -->
<!--     \label{fig:NewtonsMethod3} -->
<!--   \end{wrapfigure} -->
<p>
  As you can see from the sketch, the graphs of <m>y=x</m> and
  <m>y=\cos(x)</m> intersect exactly once. We want to use Newton's Method to find an
  approximation of the coordinates of the  point of intersection.

</p>
<p>
  `
  First obtain the iteration formula:
  <me>
    r_{n+1}=\dfrac{r_n\sin(r_n)+\cos(r_n)}{\sin(r_n)+1}.
</me>
Then use this formula  to approximate the coordinates of the point of
intersection to <m>3</m> decimal places.
</p>
</statement>
</problem>



<problem xml:id="PROBLEMSqrta">
<title>Find the Pattern</title>
  <introduction>
<image source="images/NewtonsMethod1.png" width="50%"/>
</introduction>
<task>
  <statement>
    <p>
      Apply Newton's Method to the function <m>f(x)=x^2-a</m>  to
      determine the iteration formula for approximating <m>\sqrt{a}</m>. Show
      that this is precisely the <m>(n+1)</m>st iteration you get when using
      the Babylonian method:
<me>r_{n+1}=\frac{1}{2} \left(r_n+\frac{a}{r_n} \right).</me>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Use Newton's Method on the function <m>f(x)=x^3-a</m> to obtain
      the iteration formula:
      <m>\displaystyle
      r_{n+1}=\frac{1}{3} \left(2r_n+\frac{a}{r_n^2} \right)
</m>
for  approximating <m>\sqrt[3]{a}</m>.

Notice that <m>\frac{1}{3} \left(2r_n+\frac{a}{r_n^2} \right)</m>
is the average of <m>r_n, r_n</m>, and <m>\frac{a}{r_n^2}</m>.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Obtain the iteration scheme
      <m>\displaystyle
      r_{n+1}=\frac{1}{4} \left(3r_n+\frac{a}{r_n^3} \right)
</m>
for approximating the fourth root of <m>a.</m>

Is this also an average? Of what?
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Now find an iteration scheme to find the <m>k</m>th root of <m>a,</m> if
      <m>a</m> is a positive number, and <m>k</m> is a positive integer.
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem-enumerate}[Find the pattern] -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item   Apply Newton's Method to the function <m>f(x)=x^2-a</m>  to -->
<!--     determine the iteration formula for approximating <m>\sqrt{a}</m>. Show -->
<!--     that this is precisely the <m>(n+1)</m>st iteration you get when using -->
<!--     the Babylonian method. -->
<!--                 <m>\sqrt{a}:</m> -->
<!--     <m>\displaystyle -->
<!--     r_{n+1}=\frac{1}{2} \left(r_n+\frac{a}{r_n} \right). -->
<!--     </m> -->
<!--   \item Use Newton's Method on the function <m>f(x)=x^3-a</m> to obtain -->
<!--     the iteration formula: -->
<!--     <m>\displaystyle -->
<!--     r_{n+1}=\frac{1}{3} \left(2r_n+\frac{a}{r_n^2} \right) -->
<!--     </m> -->
<!--     for  approximating <m>\sqrt[3]{a}</m>. -->

<!--     Notice that <m>\frac{1}{3} \left(2r_n+\frac{a}{r_n^2} \right)</m> -->
<!--     is the average of <m>r_n, r_n</m>, and <m>\frac{a}{r_n^2}</m>. -->
<!--   \item Obtain the iteration scheme -->
<!--     <m>\displaystyle -->
<!--     r_{n+1}=\frac{1}{4} \left(3r_n+\frac{a}{r_n^3} \right) -->
<!--     </m> -->
<!--     for approximating the fourth root of <m>a.</m> -->

<!--     Is this also an average? Of what? -->
<!--   \item Now find an iteration scheme to find the <m>k</m>th root of <m>a,</m> if -->
<!--     <m>a</m> is a positive number, and <m>k</m> is a positive integer. -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->

<!-- <figure> -->
<!--   <caption> -->
<!-- <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url> -->
<!-- </caption> -->
<!-- <image source="images/NewtonsMethod1.png" width="50%"/> -->
<!-- </figure> -->
<!-- \begin{wrapfigure}[14]{r}{2.5in} -->
<!--   \vskip-8mm  -->
<!--   \captionsetup{labelformat=empty} -->
<!--   \centerline{\includegraphics*[height=2.3in,width=2.5in]{../Figures/NewtonsMethod1}} -->
<!--   \label{fig:NewtonsMethod1} -->
<!-- \end{wrapfigure} -->

<p>

  If the initial guess is reasonably close to the root Newton's Method
  finds a very accurate approximation to the root of a function in just
  a few iterations most of the time. This made it extremely useful in
  the <m>17</m>th century when such computations were done by hand. Indeed,
  it computes the square root of a number pretty quickly even if the
  initial guess is very bad. For example in the graph at the right the
  blue curve is the graph of <m>f(x)=x^2-2.</m> We start with an initial
guess of <m>r_1=5</m> (obviously a terrible guess) and find the <m>x</m>
intercept of the red tangent line to find the next guess, <m>r_2=2.7</m>
which is better but still terrible. Repeating we generate the green
tangent line at <m>(r_2,f(r_2))</m> which crosses the <m>x-</m>axis at
<m>r_3= 1.72.</m> Finally we generate the orange tangent line at
<m>(r_3,f(r_3))</m> which crosses the <m>x-</m>axis at <m>r_4=1.44</m> which is
correct to one decimal.  If we continue one more iteration (not shown)
we get <m>r_5=1.4141</m> which is correct to three decimals.
</p>
<p>

  But this paper-and-pencil procedure is not as simple as handing
  the problem off to your favorite computational software so a natural
question to ask is, <q>Why bother, why should we learn this?</q>
</p>
<p>

  The answer is that whatever software you end up using will be
  performing either the computations above or something very like
  them. And these <term>Numerical Methods</term> are not 100% reliable.
</p>
<p>

  However if you are familiar with the limitations of the algorithm(s)
  being used you will also be aware of the limitations of your software.
  Perhaps more importantly, you are less likely to believe a wrong
  answer when you get it. Depending on what you are computing an
  incorrect approximation could mean anything from a minor annoyance --
  if you are calculating <m>\sqrt{2}</m> just for fun -- to a deadly disaster
  -- if you are designing a control procedure for a self-driving car.
</p>

<problem xml:id="PROBLEMNewtMethSignOfIterates">
  <introduction>
    <p>
      Even if you don't have any intuition into the problem a more than
      cursory understanding of the algorithm itself can be helpful.  For
      example, show that when Newton's Method is used:
</p>
</introduction>
<task>
  <statement>
    <p>
      If <m>y(r_n)</m> and <m>y^\prime(r_n)</m> have the same sign then
      <m>r_{n+1}\le r_n</m>.
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      If <m>y(r_n)</m> and <m>y^\prime(r_n)</m> have opposite signs
      then <m>r_{n+1}\ge r_n</m>.
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      Suppose you are trying to compute a numerical
      approximation of <m>\sqrt{2}</m> using an implementation of
      Newton's Method, but you accidentally enter <m>x^2+2</m> as
      you're function (instead of <m>x^2-2</m>). Explain how you can
      use the results of (a) and (b) to know that the algorithm
      is failing at the third iteration.
    </p>
  </statement>
</task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   Even if you don't have any intuition into the problem a more than -->
<!--   cursory understanding of the algorithm itself can be helpful.  For -->
<!--   example, show that when Newton's Method is used: -->
<!--   \begin{enumerate}[label={  (\alph*)}]  -->
<!--   \item If <m>y(r_n)</m> and <m>y^\prime(r_n)</m> have the same sign then -->
<!--     <m>r_{n+1}\le r_n</m>. -->
<!--   \item If <m>y(r_n)</m> and <m>y^\prime(r_n)</m> have opposite signs -->
<!--     then <m>r_{n+1}\ge r_n</m>. -->
<!--   \item Suppose you are trying to compute a numerical -->
<!--     approximation of <m>\sqrt{2}</m> using an implementation of -->
<!--     Newton's Method, but you accidentally enter <m>x^2+2</m> as -->
<!--     you're function (instead of <m>x^2-2</m>). Explain how you can -->
<!--     use the results of (a) and (b) to know that the algorithm -->
<!--     is failing at the third iteration. -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->

<p>
  So, how do you know if you should trust the approximation you get back
  from your favorite software? First, be aware of what a reasonable
  answer should be. In <xref ref="EXAMPLEnewtons-method1">Example~\</xref> it is
  clear that the root must be positive. If software tries to tell you
  that it is equal to <m>-2.5</m> you know it is lying. Second be aware of
  the ways that an approximation method might fail.
</p>

<p>
  For example, Newton's Method is not perfect. It can fail in two distinct ways:
  Subtle and Spectacular. Let's take a look at them.
</p>

</introduction>
<subsection xml:id="SUBSECTIONSpectacularFailure">
  <title>Spectacular Failure</title>

  <p>
    Newton's Method can fail spectacularly in two distinct, but related,
    ways.
    The first is very easy to spot.
  </p>

  <problem xml:id="PROBLEMNewtMethAlgGeom">
    <statement>
      <p>
        Suppose we want to find the root of <m>y=x^2-4x+7</m> and our initial
        guess is <m>r_1=2</m>.  Investigate, both algebraically and graphically,
        what happens when we apply Newton's Method to this problem. Describe
        the results of your investigations.
        
      </p>
    </statement>
  </problem>
  <p>

    Because Newton's Method requires that we divide by <m>y^\prime(r_n)</m> we
    will get an error if it happens that <m>y^\prime(r_n) =0</m>. We call this
    a spectacular failure because it is easy to spot whether we do the
    computation with a computer or with paper and pencil. Indeed, modern
    computer software is very adept at alerting us to division by zero
    errors.
  </p>

  <p>
    The second kind of spectacular failure is exemplified by the following
    problem.
  </p>


  <problem xml:id="PROBLEMNewtonsMethodOneThird">
    <introduction>
      <p>
        The only root of the function <m>f(x)=x^{1/3}</m> is zero.
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Use Newton's Method with the initial guess, <m>r_1=1</m> to
          see if it converges to zero.
          \hint{It won't.}
        </p>
      </statement>
    </task>
    <task>
      <statement>
        <p>
          Write down the iteration step (step 2) from Newton's
          Method for this function. Use this to explain why the method will
          not converge no matter what non-zero initial guess is used.
        </p>
      </statement>
    </task>
  </problem>
  <!-- \begin{embeddedproblem}  -->
  <!--   <!-\- \label{problem:NewtonsMethodOneThird} -\-> -->
  <!--   The only root of the function <m>f(x)=x^{1/3}</m> is zero.   -->
  <!--   \begin{enumerate}[label={  (\alph*)}] -->
  <!--   \item Use Newton's Method with the initial guess, <m>r_1=1</m> to -->
  <!--     see if it converges to zero.  -->
  <!--     \hint{It won't.}  -->
  <!--   \item Write down the iteration step (step 2) from Newton's -->
  <!--     Method for this function. Use this to explain why the method will -->
  <!--     not converge no matter what non-zero initial guess is used. -->
  <!--   \end{enumerate} -->

  <!-- \end{embeddedproblem} -->
  <p>
    Obviously we don't need to use Newton's Method to compute the root of
    <m>f(x)=x^{1/3}.</m> The point of this example is that Newton's Method will
    not find the root no matter how close our initial guess is. Instead it
    will continue to generate alternately positive and negative
    <q>approximations</q> to zero, that are farther and farther from zero.
  </p>



</subsection>
<subsection xml:id="SUBSECTIONSubtleFailure">
  <title>Subtle Failure</title>
  <p>
    The other way Newton's Method fails can be quite subtle. That is, it
    can converge, but not to the number we seek.
    The best way to demonstrate this is with an example.
  </p>
  <example xml:id="EXAMPLE-SubtleFailCos">
    <p>
      Suppose we wish to compute <m>\frac{\pi}{2}</m> by finding the first
      positive root of <m>\cos(x).</m> If we start with an initial guess of
      <m>r_1=.1</m> (not a great first guess, but it's not obviously horrible
      either) we get <m>r_2=10.07,</m> which certainly seems like it might be a
      problem since <m>\frac{\pi}{2}\approx 1.7.</m> If we ignore this and
      continue we get <m>r_3= 11.4,</m> and <m>r_4=10.97.</m>
    </p>
    <figure>
      <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/NewtonsMethodFail1.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[13]{r}{2.7in} -->
<!--     \vskip-6mm  -->
<!--     \captionsetup{labelformat=empty} -->
<!--     \centerline{\includegraphics*[height=2in,width=2.7in]{../Figures/NewtonsMethodFail1}} -->
<!--     \label{fig:NewtonsMethodFail1} -->
<!--   \end{wrapfigure} -->
<p>
  What's going on here?  The numbers seem to be
  converging, but they are not converging to the  answer we intended
  to find. The
  figure at the right shows what the difficulty is.
</p>
<p>

  In a nutshell, our initial guess was too far away from the
  root. The slope of the tangent line at <m>(0.1, \cos(0.1))</m> is
  <m>-\sin(0.1)\approx -0.1</m> which means that the tangent line
  (in red) decreases from left to right, but also
  that its slope is very shallow. Thus the tangent line crosses the
  <m>x-</m>axis at about <m>r_2=10.07,</m> very far from the root we seek. Now
  it happens that <m>10.07</m> is actually pretty close to another
  root of our function: <m>7\pi/2.</m> So continued iterations of Newton's
  Method will settle in on the root at <m>7\pi/2</m>. But the damage has
  already been done. We've found a legitimate root but not he one we
  intended to find.
</p>
<p>
  
  We call this a subtle failure because Newton's Method will converge
  without complaint. None of the computations will seem suspicious. A
  software implementation of Newton's Method for this problem using
  this initial guess will return a reasonable looking, but wrong,
  number.  Although it is glaringly obvious what goes wrong when we
  draw a picture of each successive approximation the fact is if we
  use a software to compute the root most of the time there would be
  no pictures. Notice that, unlike the spectacular failure above there
  is nothing in the calculations being performed that could be
  detected in software to let the human in charge know that things
  have gone wrong. So, if you rely on software it is essential that
  you take the time to consider the <q>reasonableness</q> of the answer
  you obtain. If this is not understood there is a real risk that you
  could accept a
  ridiculous answer as correct.
</p>
</example>

<p>
  The problem of converging to a wrong answer is particularly acute
  when a function has two roots which are very close together, for
  example if <m>f(x) = (10x^2-21x+11)(x-0.05)(x^3+7).</m>
</p>
<problem xml:id="PROBLEMNewtMethHardCubic">
  <statement>
    <p>
      Find approximations to all real roots of
      <me>
        f(x) =
        t  (10x^2-21x+11)(x-0.05)(x^3+7).
      </me>
    </p>
  </statement>
</problem>
<p>

  From the previous examples it should be clear that it is important
  that the initial guess be sufficiently close to the root we seek that the
  iterations will converge to the desired root. This, of course, begs
  the question, <q>How close should our initial guess be?</q> This is
  actually a hard question. Since we don't yet possess all of the
  knowledge and skills needed we can't answer it in any definite way. So
  we'll just say that in general your initial guess should be as close
  as you can make it.
</p>
<p>

  But take care. As we saw in
  <xref ref="PROBLEMNewtonsMethodOneThird">Problem~\</xref> sometimes even having a
  very accurate first guess is not sufficient.
</p>


<problem>
  <introduction>
    <p>
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        Use Newton's Method to find approximations to the positive
        roots closest to zero of each of the following functions.
        (Clearly you can use Algebra and Trigonometry to compute them
        exactly. The point here is to see how good our guesses must
        sometimes be in order for Newton's Method to work.}
        <ol>
          <li>
            <p>
              <m>y(x)=x(x^2-.01)</m>
            </p>
          </li>
          <li>
            <p>
              <m>y(x)=(x^2-9)(x^2-.01)</m>
            </p>
          </li>
          <li>
            <p>
              <m>y(x)=x^2\sin(4x)</m>
            </p>
          </li>
          <li>
            <p>
              <m>y(x)=x^2\cos(4x)</m>
            </p>
          </li>
        </ol>

      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        If we were to next ask you to find approximations of the
        negative roots closest to zero of each of these functions would you
        need to use Newton's Method again? Explain.
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem-enumerate}  ;;; MULTILEVEL PROBLEM -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Use Newton's Method to find approximations to the -->
<!--     positive roots closest to zero of each of the following functions. -->
<!--     \comment{Yes, we know you can find them exactly using -->
<!--       Algebra and Trigonometry. The point here is to see how good our -->
<!--       guesses have to be sometimes for Newton's Method to work.} -->

<!--       <ol> -->
<!--         <li> -->
<!--           <p> -->
<!--             <m>y(x)=x(x^2-.01)</m> -->
<!--           </p> -->
<!--         </li> -->
<!--         <li> -->
<!--           <p> -->
<!--             <m>y(x)=(x^2-9)(x^2-.01)</m> -->
<!--           </p> -->
<!--         </li> -->
<!--         <li> -->
<!--           <p> -->
<!--             <m>y(x)=x^2\sin(4x)</m> -->
<!--           </p> -->
<!--         </li> -->
<!--         <li> -->
<!--           <p> -->
<!--             <m>y(x)=x^2\cos(4x)</m> -->
<!--           </p> -->
<!--         </li> -->
<!--       </ol> -->

<!--   \item If we were to next ask you to find approximations of the -->
<!--     negative roots closest to zero of each of these functions would you -->
<!--     need to use Newton's Method again? Explain. -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->


<problem>
  <introduction>
    <p>
      Do not try to answer the questions in this problem
      analytically. Use a graphing calculator, or graphing software to
      explore these questions visually.

      The function
      <me>
        f(x)=4x^{3}-30x^{2}+72x-52.
      </me>
      has exactly one real root and it is between one and two.
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        Show that with an initial guess, <m>r_1 \gt 2</m>,
        Newton's Method almost never converges to the root.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        We said <q>almost never</q> in part (a) because there is a
        small interval of numbers greater than <m>2</m> with the property that Newton's Method
        will converge if <m>r_1</m> is any number in the
        interval. Find an interval that works. \comment{It doesn't have to be
        the largest possible interval.}
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Show that if you start with an initial guess of <m>r_1=2</m> or
        <m>r_1=3</m> Newton's Method will not even generate the first iterate:
        <m>r_2.</m> Explain.
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   Do not try to answer the questions in this problem -->
<!--   analytically. Use a graphing calculator, or graphing software to -->
<!--   explore these questions visually. -->

<!--   The function -->
<!--   <me> -->
<!--   f(x)=4x^{3}-30x^{2}+72x-52. -->
<!--   </me> -->
<!--   has exactly one real root and it is between one and two. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Show that with an initial guess, <m>r_1 \gt 2</m>, -->
<!--     Newton's Method almost never converges to the root. -->
<!--   \item We said <q>almost never</q> in part (a) because there is a -->
<!--     small interval of numbers greater than <m>2</m> with the property that Newton's Method -->
<!--     will converge if <m>r_1</m> is any number in the -->
<!--     interval. Find an interval that works. \comment{It doesn't have to be -->
<!--       the largest possible interval.} -->
<!--   \item Show that if you start with an initial guess of <m>r_1=2</m> or -->
<!--     <m>r_1=3</m> Newton's Method will not even generate the first iterate: -->
<!--     <m>r_2.</m> Explain. -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->


<problem>
  <statement>
    <p>
      Suppose that a cubic polynomial has three real roots, <m>a</m>, <m>b</m>,
      and <m>c</m> and  that two of them, <m>a</m> and <m>b</m> are known.  We wish
to approximate the third. Show that if we take the average of <m>a</m>
and <m>b</m> as our initial guess, Newton's Method will find the exact
value of the third root, <m>c</m>, in one iteration.
</p>
</statement>
</problem>


</subsection>

</section>
<section xml:id="SECTIONeulers-method">
<title>Euler's Method</title>

<figure>
  <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/EulerFig1.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[10]{r}{2in} -->
<!--   \captionsetup{labelformat=empty} -->
<!--   \vskip-10mm  -->
<!--   \includegraphics*[height=1.8in,width=2in]{../Figures/EulerFig1} -->
<!--   \label{fig:EulerFig1} -->
<!-- \end{wrapfigure} -->
<p>
  Suppose <m>B</m> is a point on the graph of an unknown function <m>y(x)</m> (in
  green in the figure at the right). Suppose further that if the line
tangent to the graph at <m>B</m> (in red) crosses the <m>x</m>-axis at <m>(a, 0)</m>
as shown.
</p>
<p>

We wish to address the following question\aside{The line segment <m>AC</m>
is called the subtangent of the graph. In the seventeenth
mathematics century was still strongly tied to Greek geometry so
some of the early, pre-Calculus efforts to find the tangent lines
were aimed at finding the length of the subtangent of a
curve. Finding length of <m>\overline{CA}</m> is equivalent to finding
the derivative of <m>y</m> at <m>B</m> because if <m>B</m> and <m>C</m> are known then
the slope of the curve at <m>B</m> is equal to
<m>\frac{\overline{BC}}{\overline{AC}}</m>.}: <q>Is there a curve which
passes through the point <m>(0,
1)</m> with the property that the distance from <m>A</m> to
<m>C</m> is equal to <m>1</m> regardless of the location of <m>B</m> on the graph.</q>
</p>
<p>

  At <m>B</m> form the differential right triangle with the infinitesimal
  vertical displacement <m>\dx{y}</m> and the infinitesimal horizontal
  displacement <m>\dx{x}</m>, as shown. Then the right triangle with sides of
  length <m>y</m> and <m>1</m> is proportional to the differential triangle. By
  the properties of proportional triangles this curve must satisfy the
  differential equation: <m>  \dfdx{y}{x} = y</m>.
</p>
<p>

Since we specified that the curve must pass through the point <m>(0, 1)</m>
we see that we need to find a function <m>y(x)</m> that satisfies the
following two conditions:
<me>
  \label{IVP:ExpDiffeq1}
  \dfdx{y}{x} = y, \text{ and }  y(0)=1.
</me>
A problem like the one stated in <xref ref="IVPExpDiffeq1">Formula</xref> is
called an <term>Initial Value Problem</term>, or IVP. We will give a formal
definition below (<xref ref="DEFIVP">Definition</xref>).
</p>
<p>

  We do not know a formula for <m>y</m> which will satisfy
  <xref ref="IVPExpDiffeq1">IVP~\</xref>, nor do we have the tools to find such a
  formula, yet.  We will return to this question in
  <xref ref="CHAlast-elem-funct">Chapter~</xref>) where we will solve
  <xref ref="IVPExpDiffeq1">IVP~</xref>) exactly. For the moment we will be
  satisfied if we can find an approximate graph of the solution.  That
  will give us a general sense of its shape.
</p>
<p>


  The initial value in <xref ref="IVPExpDiffeq1">IVP~</xref>) shows that  the curve
  passes through the point <m>(0,1)</m>.  From the differential equation in
  <xref ref="IVPExpDiffeq1">IVP~</xref>)  we see that
  <me>
    \eval{\dfdx{y}{x}}{x}{0} = y(0) =1.
</me>
which means that the curve passes through the point <m>(0,1)</m> with a
slope equal to <m>1</m>.  So the equation of the line
tangent to our curve is
<me>
  y-1=\underbrace{\left[\eval{\dfdx{y}{x}}{x}{0}\right]}_{=y(0)=1}(x-0)
  \text{ or }
  y=x+1.
</me>
This is not a lot to work with, but let's not set our sights too high.
</p>
<p>

  By the Principle of Local Linearity, the line tangent to the curve and
  the curve itself are going to be nearly indistinguishable near to the
  point <m>(0,1)</m>. Moreover, we can find any point on the tangent line
  since we have its equation.  If we increment the <m>x</m>-coordinate just a
  little bit while staying on the tangent line then the corresponding
  <m>y-</m>coordinate on the tangent line will be close to the <m>y-</m>coordinate
  on the curve. So we can use the <m>y</m>-coordinate on the tangent line
  (which we know) to approximate the <m>y</m>-coordinate on the curve (which
  we don't know).
</p>


<figure>
  <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/exp-piecewise-linear2.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[]{r}{3in} -->
<!-- \captionsetup{labelformat=empty} -->
<!-- \centerline{\includegraphics*[height=1.6in,width=3in]{../Figures/exp-piecewise-linear2}} -->
<!-- \label{fig:exp-piecewise-linear2} -->
<!-- \end{wrapfigure} -->
<p>

  Let's say we increase <m>x</m> by <m>0.1</m> so that <m>x=0.1</m>.  The
<m>y</m>-coordinate on the line tangent to the curve at <m>x=0.1</m> is <m>1.1</m>
(since the equation of our tangent line is <m>y=x+1</m>).
</p>
<p>

  We now have two points on our curve: <m>(0,1)</m> and <m>(0.1, 1.1).</m> The
  point <m>(0.1, 1.1)</m> isn't on the curve, but it's close. Remember we're
  only trying to approximate the curve. Connecting these with a straight
  line we have the red segment on the graph at the right.  So far, so
  good.
</p>
<p>

  Next we increment <m>x</m> by <m>0.1</m> again, to <m>x=0.2</m>.  We would really
  like to have the equation of the line tangent to the curve at
  <m>(0.1, y(0.1))</m> but we simply have no way to obtain it. All we have is
  the point <m>(0.1, 1.1)</m>. But we know that <m>y(0.1)\approx1.1</m> so the
  differential equation from <xref ref="IVPExpDiffeq1">IVP~</xref>) tells us that
  <m>\eval{\dfdx{y}{x}}{x}{0.1}\approx1.1</m> also. Thus we see that the curve
  will pass (approximately) through the point <m>(0.1, 1.1)</m> with slope
  (approximately) equal to <m>1.1</m>. Therefore the equation of the line
  tangent to the curve at (approximately) <m>(0.1, 1.1)</m> will be
  <m>y-1.1=1.1(x-0.1)</m> and as long as we don't move too far the
  Principle of Local Linearity guarantees that this line and the curve
  we seek are close together. So we use the blue line segment from
  <m>(0.1, 1.1)</m> to <m>(0.2, 1.21)</m> in our figure above to approximate the
  curve on the interval <m>(0.1, 0.2)</m>.
</p>
<p>



  We now repeat this process to compute the points:<m>(0.3,1.331)</m>,
  <m>(0.4,1.4641)</m>, <m>(0.5,1.61051)</m>, and so on.  Plotting these points and
  connecting them with straight line segments gives us the rest of the
  sketch above.
</p>


<figure>
  <caption>
<url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
</caption>
<image source="images/exp-piecewise-linear3.png" width="50%"/>
</figure>
<!-- \begin{wrapfigure}[15]{l}{2.5in} -->
<!-- \captionsetup{labelformat=empty} -->
<!-- \centerline{\includegraphics*[height=2.1in,width=2.5in]{../Figures/exp-piecewise-linear3}} -->
<!-- \label{fig:exp-piecewise-linear3} -->
<!-- \end{wrapfigure} -->
<p>

  At each step we use the previous approximation to compute the next, so
  it would be miraculous if we actually found exactly the points on the
  graph of our curve.  But it should be clear  that the curve we've drawn
  will at least resemble the desired curve, as long as we don't
  stray too far from our initial point <m>x=0</m>.
  The sketch below shows our approximation and the actual solution
  on the same set of axes\aside{In practice of course, we wouldn't know the
  actual solution -- if we knew that there would be no reason to find an
  approximation -- but in this case we (the authors) do know.}.
</p>
<p>

  The solution of this particular IVP  turns out to be
  incredibly useful in mathematics, theoretical physics, engineering,
  and science and technology in general.  We will be revisiting it in
  the next chapter.
</p>
<p>

  The procedure we have just outlined is known as <term>Euler's Method</term>;
  named for the great eighteenth century mathematician Leonhard
  Euler. For now we'll focus on how to use Euler's Method to find an
  approximate solution of an arbitrary <term>Initial Value Problem</term>.
</p>
<p>

  We define an
  Initial Value Problem formally as follows.
</p>

<definition xml:id="DEFINITIONdef:IVP">
  <title>Initial Value Problem</title>
  <statement>
    <p>
      <!-- \label{def:IVP} -->
      An <term>Initial Value Problem</term> is a differential equation of the
      form <me>\dfdx{y}{x}=f(x,y),</me> along with an <term>Initial Value</term> <me>y(x_0)=y_0.</me>
    </p>
  </statement>
</definition>
<p>

  Don't let the formalism of this definition scare you. All it says is
  that at every point <m>(x,y)</m> the slope of <m>y(x)</m>,
  <m>\left(\dfdx{y}{x}\right)</m>, is given by some formula, <m>f(x,y)</m>,
  which may involve both <m>x</m> and <m>y</m>\aside{In our problem above we had
  <m>\dfdx{y}{x}=f(x,y)=y</m>.}, and that we know the value of <m>y(x)</m> for a
  single value of <m>x</m>. Specifically, at  <m>x=x_0</m>.
</p>
<p>

  To write down Euler's Method clearly we will need some
  notation.
  We know that the equation of the tangent line to the curve <m>y=y(x)</m> at
  the point <m>(x_0,y_0)</m> is given by
  \begin{align*}
  y\amp =y_0+\left(\eval{\dfdx{y}{x}}{(x,y)}{(x_0,y_0)}\right)(x-x_0)
  \amp =y_0+f(x_0,y_0)(x-x_0 ).
  \end{align*}
  So if we choose <m>x_1</m> very close to <m>x_0</m> and compute
  <m>
    y_1=y_0+f(x_0,y_0 )(x_1-x_0 )
  </m>
  then <m>(x_1,y_1)</m> would be approximately on the curve. In this way we can generate
  a sequence of points
  <m>(x_0,y_0 ), (x_1,y_1 ), (x_2,y_2 ), (x_3,y_3 ),\ldots</m> which are
  approximately on the curve.  Connecting them with straight line
  segments should provide an
  approximate graph of the curve.
</p>
<p>
  Formalizing all of this we have:
</p>
<algorithm>
  <title>Euler's Method</title>
  <p>
    Given an IVP:
    <me>
      \dfdx{y}{x} = f(x,y),\ \ \ y(x_0)=y_0.
    </me>
    approximate points <m>(x_1,y_1 ), (x_2,y_2 ), (x_3,y_3 ),\ldots</m>   on
    the graph  of <m>y(x)</m> by computing:
    <me>
      y_{n+1}=f(x_n,y_n )(x_{n+1}-x_n)+y_n
    \text{ for } n=1, 2, 3, \ldots.</me>
  </p>
</algorithm>
<p>
  At each iteration the value of <m>y</m> has been approximated, so the next
  approximation is probably not as good. Thus, as we move further from
  our initial value <m>(x_0, y_0)</m> our approximation probably deviates
  further away from the actual curve.  However,  near to the
  initial value, <m>(x_0,y_0)</m> we should have a reasonable approximation
  to the curve <m>y=y(x)</m>. The next two
  problems demonstrate this.
</p>
<problem xml:id="embed:EulerSine">
  <statement>
    <p>
      <!-- \label{embed:EulerSine} -->
      Observe that <m>y=\sin(x)</m> satisfies the IVP
      <me>
        \dfdx{y}{x}=\cos(x),\ \ \  y(0)=0.
      </me>

      Use Euler's Method on this IVP to complete the table. Then plot the
      points you generated and the graph of <m>y=\sin(x)</m> on the same
      set of axes so you can compare them.
    </p>

    <image source="images/EulerTable1.png" width="60%" />
    <!-- \centerline{\includegraphics*[height=1.4in,width=5.1in]{../Figures/EulerTable1}} -->
  </statement>
</problem>


<problem xml:id="embed:EulerCosine">
  <statement>
    <p>
      <!-- \label{embed:EulerCosine} -->
      Observe that <m>y=\cos(x)</m> satisfies the IVP
      <me>
        \dfdx{y}{x}=-\sin(x),\ \ \  y(0)=1.
      </me>

      Use Euler's Method on this IVP to complete the following table.
      Then plot the points you generated and the graph of <m>y=\cos(x)</m> on
      the same
      set of axes so you can compare them.
    </p>
    <image source="images/EulerTable2.png" width="60%" />
    <!-- \centerline{\includegraphics*[height=1.5in,width=5.1in]{../Figures/EulerTable2}} -->
  </statement>
</problem>


<problem>
  <introduction>
    <p>
      Use Euler's Method to approximate the solutions of the given IVPs
      by constructing a table like the ones in
      <xref ref="EMBEDEulerSine">Problems</xref>
      <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found,
      connecting them with straight line segments.
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=y^2,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=y^3,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=y^4,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=y^5,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   Use Euler's Method to approximate the solutions of the given IVPs -->
<!--   by constructing a table like the ones in -->
<!--   <xref ref="EMBEDEulerSine">Problems</xref> -->
<!--   <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found, -->
<!--   connecting them with straight line segments. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--     \item <m>\dfdx{y}{x}=y^2,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=y^3,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=y^4,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=y^5,\ \ \ y(0)=1</m> -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->

<problem>
  <introduction>
    <p>
      Use Euler's Method to approximate the solutions of the given IVPs
      by constructing a table like the ones in
      <xref ref="EMBEDEulerSine">Problems</xref>
      <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found,
      connecting them with straight line segments.
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{1}{y},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{1}{y^2},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{1}{y^3},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{1}{y^4},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   Use Euler's Method to approximate the solutions of the given IVPs -->
<!--   by constructing a table like the ones in -->
<!--   <xref ref="EMBEDEulerSine">Problems</xref> -->
<!--   <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found, -->
<!--   connecting them with straight line segments. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--     \item <m>\dfdx{y}{x}=\frac{1}{y},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{1}{y^2},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{1}{y^3},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{1}{y^4},\ \ \ y(1)=1</m>  -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->


<problem>
  <introduction>
    <p>
      Use Euler's Method to approximate the solutions of the given IVPs
      by constructing a table like the ones in
      <xref ref="EMBEDEulerSine">Problems</xref>
      <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found,
      connecting them with straight line segments.
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=xy,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=x^2y,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=xy^2,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=x^2y^2,\ \ \ y(0)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{x}{y},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{x^2}{y},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{x}{y^2},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{x^2}{y^2},\ \ \ y(1)=1</m>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        <m>\dfdx{y}{x}=\frac{x^2}{y^2},\ \ \ y(1)=2</m>
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem}  -->
<!--   Use Euler's Method to approximate the solutions of the given IVPs -->
<!--   by constructing a table like the ones in -->
<!--   <xref ref="EMBEDEulerSine">Problems</xref> -->
<!--   <xref ref="EMBEDEulerCosine">and</xref>. Then plot the points you found, -->
<!--   connecting them with straight line segments. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--     \item <m>\dfdx{y}{x}=xy,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=x^2y,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=xy^2,\ \ \ y(0)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=x^2y^2,\ \ \ y(0)=1</m>  -->
<!--     \item <m>\dfdx{y}{x}=\frac{x}{y},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{x^2}{y},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{x}{y^2},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{x^2}{y^2},\ \ \ y(1)=1</m> -->
<!--     \item <m>\dfdx{y}{x}=\frac{x^2}{y^2},\ \ \ y(1)=2</m> -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem}     -->



<problem xml:id="PROBLEMTractrix">
  <introduction>
      <image source="images/Tractrix.png" width="50%"/>
<!-- \begin{wrapfigure}[10]{r}{2.5in} -->
<!--       \captionsetup{labelformat=empty} -->
<!--       \vskip-4mm -->
<!--       \includegraphics*[height=1.5in,width=2.5in]{../Figures/Tractrix} -->
<!--       \label{fig:TractrixEuler} -->
<!--       \end{wrapfigure} -->
    <p>
      Consider the top view of a tractor-trailer as it turns, as shown at
      the right.  Initially, the center of the rear axle of the tractor is
      at the origin and the center of the rear axle of the trailer is at
      the point <m>(1,0)</m>.  The tractor pulls the front wheels vertically up
      the <m>y</m>-axis and we assume that the rear wheels don't slip.
      
      The path that the center of the rear axle follows is called a
      tractrix from the Latin verb \foreign{trahere}, meaning <q>to drag or
      pull.</q>

    </p>
  </introduction>
  <task>
    <statement>
      <p>
        Show that the tractrix must satisfy the Initial Value Problem
        <me>

          \label{eq:TractrixIVP}
          \dfdx{y}{x}=-\frac{\sqrt{1-x^2 }}{x}\ \ y(1)=0.
          
        </me>
        \hint{Find a differential triangle and an ordinary triangle which
        are proportional..}
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Apply Euler's Method to complete the
        following table to
        approximate the tractrix.
        \leftline{\includegraphics*[height=1.25in,width=5in]{../Figures/EulerTable3}}
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Plot the points obtained in part b to see if this looks like
        the path the rear axle of the trailer would take.
      </p>
    </statement>
  </task>
</problem>

<problem xml:id="PROBLEMpursuit">
  <introduction>
    <figure>
      <caption>
      This figure needs a caption.</caption>
      <image source="images/PursuitCurve2.png" width="50%"/>
    </figure>
    <!-- \begin{wrapfigure}[11]{r}{3in} -->
    <!--     \captionsetup{labelformat=empty} -->
    <!--     \vskip-8mm -->
    <!--   \centerline{\includegraphics*[height=2in,width=3in]{../Figures/PursuitCurve2}} -->
    <!-- \label{fig:PursuitCurve2Euler} -->
    <!-- \end{wrapfigure} -->
    <p>
      Suppose a rocket <m>R</m> travels up the line <m>x=1</m> at a constant speed
      <m>v</m>. As the rocket passes through the point <m>(1,0)</m>, a  missile
      <m>M</m> is fired from the origin directly at the rocket.  Assume that the
      missile travels at a speed which is <m>\frac32</m> times the speed of the
      rocket and is always aimed directly at the rocket. At time <m>t</m> the
      missile is at the point <m>M(x,y)</m> and the rocket is at the point
      <m>R(1,vt)</m> We want to find the path the missile will follow.  The
      diagram at the right shows the situation at time <m>t</m>.%
    </p>
  </introduction>
  <task>
    <statement>
      <p>
        Find <m>s</m> if <m>s</m> denotes the length of the the missile's path
        at time <m>t</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Show that the missile's path must satisfy the IVP
        <me>
          \dfdx{y}{x}=\frac{\frac{2s}{3}-y}{1-x},\ \       y(0)=0.r
        </me>

      </p>
    </statement>


    <hint>
      <p>
        Find a triangle which is proportional to the differential
        triangle shown.}
      </p>
    </hint>
  </task>
  <task>
    <statement>
      <p>
        Apply Euler's Method to fill in the following
        table.
        \leftline{\includegraphics*[height=1.25in,width=5in]{../Figures/EulerTable4}}
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Plot the points obtained in part b to see if this resembles the
        path you think the missile would follow.
      </p>
      <p>
        We will re-visit this problem and find the exact solution in <xref ref="SUBSECTIONpursuit"></xref>.
      </p>
    </statement>
  </task>
</problem>
<!-- \begin{embeddedproblem}  -->
<!--   <!-\- \label{PROBLEMpursuit} -\-> -->
<!--   \begin{wrapfigure}[11]{r}{3in} -->
<!--     \captionsetup{labelformat=empty} -->
<!--     \vskip-8mm  -->
<!--   \centerline{\includegraphics*[height=2in,width=3in]{../Figures/PursuitCurve2}} -->
<!-- \label{fig:PursuitCurve2Euler} -->
<!-- \end{wrapfigure} -->
<!-- Suppose a rocket <m>R</m> travels up the line <m>x=1</m> at a constant speed -->
<!-- <m>v</m>. As the rocket passes through the point <m>(1,0)</m>, a  missile -->
<!-- <m>M</m> is fired from the origin directly at the rocket.  Assume that the -->
<!-- missile travels at a speed which is <m>\frac32</m> times the speed of the -->
<!-- rocket and is always aimed directly at the rocket. At time <m>t</m> the -->
<!-- missile is at the point <m>M(x,y)</m> and the rocket is at the point -->
<!-- <m>R(1,vt)</m> We want to find the path the missile will follow.  The -->
<!-- diagram at the right shows the situation at time <m>t</m>.%  -->
<!--     \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Find <m>s</m> if <m>s</m> denotes the length of the the missile's path -->
<!--     at time <m>t</m>. -->
<!--   \item Show that the missile's path must satisfy the IVP -->
<!--     <me> -->
<!--     \dfdx{y}{x}=\frac{\frac{2s}{3}-y}{1-x},\ \       y(0)=0.r -->
<!--     </me> -->
<!--     \hint{Find a triangle which is proportional to the differential -->
<!--       triangle shown.} -->
<!--   \item Apply Euler's Method to fill in the following -->
<!--     table. -->
<!--     \leftline{\includegraphics*[height=1.25in,width=5in]{../Figures/EulerTable4}} -->

<!--                                                       \item Plot the points obtained in part b to see if this resembles the -->
<!--     path you think the missile would follow. -->
<!--   \end{enumerate} -->
<!--   We will re-visit this problem and find the exact solution in <xref ref="SUBSECpursuit">Section~</xref> -->
<!-- \end{embeddedproblem} -->


</section>
<section xml:id="SECTIONmore-high-deriv">
  <title>Higher Derivatives, Lagrange, and Taylor  </title>

  <figure>
    <caption>
      <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
    </caption>
    <image source="images/HigherLagr1.png" width="50%"/>
  </figure>
  <!-- \begin{wrapfigure}[]{l}{2in} -->
  <!--   \captionsetup{labelformat=empty} -->
  <!--   \vskip-8mm  -->
  <!--   \centerline{\includegraphics*[height=2.5in,width=2in]{../Figures/HigherLagr1}} -->
  <!--   \label{fig:HigherLagr1} -->
  <!-- \end{wrapfigure} -->
  <p>

    In the diagram at the left, we see a pendulum of length <m>l</m> with an
    object of mass <m>m</m> at the end. If the object is moved away from its
    equilibrium point the pendulum will begin to swing back and
    forth. If we disregard  friction the angle <m>\theta</m>, that the pendulum forms
    with a vertical line would oscillate in a
    manner very like the motion of the <term>Simple Harmonic Oscillators</term>
    (SHO) that we saw in <xref ref="SECsimple-harm-oscill">Section</xref>.
  </p>
  <p>

    If the motion of the pendulum actually is an SHO then it will
    necessarily satisfy <xref ref="EQSHO">Equation</xref>. In this case that means
    that
    <me>
      \dfdxn{\theta}{t}{2}=-\omega^2\theta,
    </me>
    for some constant value of <m>\omega</m>.
    We'll investigate to see if that is true.
  </p>
  <p>


    To keep our model simple we assume that <m>-\pi\lt \theta \lt \pi</m> and
    we will ignore any sort of resistance.  The only force we are
    considering is the (vertical) force due to gravity <m>mg</m>. As before
    this vertical force will resolve into the centripetal force along the
    length of the pendulum, and the tangential force in the direction of
    motion. We will focus our attention on the tangential force.
  </p>
  <p>

    If <m>\theta</m> is measured in radians then the length of the arc traced
    by the object is <m>s=l\theta</m>.  Thus we see that the tangential
    component of the force due to gravity is given by <m>mg\sin(\theta)</m> as
    shown. Notice that when <m>\theta\gt 0</m> this tangential force points to
    the left and when <m>\theta\lt 0</m> it points to the right (not
    shown). This says that the sign of the tangential force <m>F</m> is the
    opposite of the sign of <m>\theta</m>. When <m>\theta</m> is in the interval
    <m>[-\pi, \pi]</m> <m>\theta</m> and <m>\sin(\theta)</m> have the same sign.  Thus We
    have <m>F=-mg\sin(\theta)</m>. Using Newton's Second Law,
    <m>\text{Force} = \text{mass}\cdot\text{acceleration}</m>, we see that the
    motion of a pendulum satisfies the equation
    <me>
      m\dfdxn{s}{t}{2}=-mg\sin(\theta).
    </me>
    Finally, since <m>s=l\theta</m> we have
    <m>\dfdxn{s}{t}{2}=\dfdxn{(l\theta)}{t}{2}</m>. Using the Constant Rule
    (twice) we see that <m>\dfdxn{s}{t}{2}=l\dfdxn{\theta}{t}{2}</m>. Thus
    <me>
      \dfdxn{\theta}{t}{2}=\frac{g}{l}\sin(\theta).\label{eq:SHO3}
    </me>
    But it does not satisfy <xref ref="EQSHO">Equation~</xref>). Therefore a
    swinging pendulum is not a Simple Harmonic Oscillator. Its
    motion is slightly more complex.
  </p>

  <figure>
    <caption>
      <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
    </caption>
    <image source="images/SinApprox1.png" width="50%"/>
  </figure>
  <!-- \begin{wrapfigure}[7]{r}{2.4in} -->
  <!--   \vskip-4mm  -->
  <!--   \captionsetup{labelformat=empty} -->
  <!--   \centerline{\includegraphics*[height=1.2in,width=2.4in]{../Figures/SinApprox1}} -->
  <!--   \label{fig:SinApprox1} -->
  <!-- \end{wrapfigure} -->
  <p>

    But only slightly.
  </p>
  <p>

    By examining the graphs of <m>y=\sin(x)</m> and <m>y=x</m> we can see the that
    for values of <m>x</m> close to zero the graphs are nearly identical. Thus,
    when the angle <m>\theta</m> is very small <m>\sin(\theta)</m> and <m>\theta</m> are
    very nearly equal.  In that case if we replace <m>\sin(\theta)</m> with
    <m>\theta</m> in <xref ref="EQSHO3">Equation~</xref>) we see the the motion of a
    pendulum approximately satisfies the equation
    <me>
      <!-- \label{eq:SHO4} -->
      \dfdxn{\theta}{t}{2}=-\frac{g}{l}\theta,
    </me>
    which we recognize as <xref ref="EQSHO">Equation~</xref>) with <m>\omega^2 =
    \frac{g}{l}.</m>
  </p>


  <exercise>
    <statement>
      <p>
        Show that the equation of the line tangent to <m>y=\sin(x)</m> at <m>x=0</m>
        is <m>y=x</m>.
      </p>
    </statement>
  </exercise>

  <figure>
    <caption>
      <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">This figure needs a caption.</url>
    </caption>
    <image source="images/HigherLagr4.png" width="50%"/>
  </figure>
  <!-- \begin{wrapfigure}[]{l}{2.3in} -->
  <!--   \captionsetup{labelformat=empty} -->
  <!--       \centerline{\includegraphics*[height=1.2in,width=2in]{../Figures/HigherLagr4}} -->
  <!--   \label{fig:HigherLagr3} -->
  <!-- \end{wrapfigure} -->
  <p>

    Approximating <m>\sin(x)</m> by its tangent line at <m>x=0</m> works well for
    values of <m>x</m> close to zero. We have not been very precise about the
    meaning of <q>close to zero</q> but it should be clear that if <m>\theta</m>
    is too large <xref ref="EQSHO3">Equation~</xref>) will no longer serve as a good
    model.
  </p>
  <p>

    Notice that the function <m>y(x) = x</m> is a first degree polynomial. Is
    it possible that a polynomial with a higher degree give us a better
    approximation?  Can we find a polynomial with degree greater than one
    that approximates the graph of <m>y=\sin(x)</m>?
  </p>
  <p>



    At the left we compare the graphs of <m>y=x</m> (in red),
    <m>y=\sin(x)</m> (in blue), and <m>y=x-\frac{x^3}{6}</m> (in green) on the same
    set of axes. It should be clear <m>y=x-\frac{x^3}{6}</m> is a better
    approximation to <m>y=\sin(x)</m> than <m>y=x</m> in the sense that the graph of
    <m>y=x-\frac{x^3}{6}</m> stays closer to the graph of <m>y=x</m> on a wider
    interval than the graph of <m>y=x</m>.
  </p>
  <p>

    So it seems reasonable to suppose that the differential equation
    <me>
      <!-- \label{eq:SHO5} -->
      \dfdxn{\theta}{t}{2}=-\frac{g}{l}\left(\theta-\frac{\theta^3}{6}\right),\
      \theta(t)=0,
    </me>
    if we can solve it, would serve as a better model for the motion of a
    pendulum than <xref ref="EQSHO4">Equation</xref>. Unfortunately we do not yet have
    the tools to solve <xref ref="EQSHO5">Equation</xref>, but the notion of
    approximating a complex function, like <m>\sin(x)</m>, with a polynomial  will turn out
    to be very useful so we will explore it for a bit before we go on.
    We will again switch to Lagrange's prime notation because in this
    context Lagrange's notation really shines. Indeed, it was while
    he was looking at similar problems that Lagrange invented his prime
    notation in the first place.
  </p>
  <p>

    The key is to look at higher derivatives of <m>\sin(x)</m>.  Recall that
    for <m>y=f(x)</m>, Lagrange introduced the notation and terminology
    <md>
      <mrow>  \dfdx{y}{x}\amp = f^\prime(x) \text{ (first derivative)}</mrow>
      <intertext>Extending this further, we have</intertext>
      <mrow>  \dfdxn{y}{x}{2} \amp = f^{\prime\prime}(x)=f^{(2)}(x) \text{
      (second derivative)}</mrow>
      <mrow>  \dfdxn{y}{x}{3} \amp = f^{\prime\prime\prime}(x)=f^{(3)}(x) \text{ (third derivative)}</mrow>
      <mrow>  \dfdxn{y}{x}{4} \amp = f^{\prime\prime\prime\prime}(x)=f^{(4)}(x) \text{ (fourth
      derivative)}</mrow>
      <mrow>  \amp  \vdots</mrow>
    </md>
  </p>

  <exercise xml:id="EXERCISEGenTan">
    <statement>
      <p>
        Show that the equation of the line tangent to the graph of an
        arbitrary (differentiable) function <m>f(x)</m> at <m>x=0</m> is given by
        <me>
          y(x)=f(0)+f^\prime(0)\cdot x.
        </me>
      </p>
    </statement>
  </exercise>
  <p>
    Applying the result of <xref ref="PROBGenTan">Drill</xref> to <m>f(x)=\sin(x)
    </m> we see that the equation of the line tangent to the graph of
    <m>y=\sin(x)</m> at <m>(0,0)</m> is given by
    <me>
      y(x) = \sin(0)+\cos(0)\cdot x = x.
    </me>
  </p>
  <exercise>
    <introduction>
      <p>
        This drill demonstrates how we can obtain a first degree polynomial
        that approximates <m>f(x_0)</m> near <m>x=0</m>.
        
        Suppose that  <m>f(x)</m> is some (differentiable) function and that
        <m>l(x) =A+Bx</m>.
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Show that if <m>f(0)=l(0)</m> then <m>A=f(0).</m>
        </p>
      </statement>
    </task>
    <task>
      <statement>
        <p>
          Show that if <m>f^\prime(0)=l^\prime(0)</m> then
          <m>B=f^\prime(0).</m>
        </p>
      </statement>
    </task>
  </exercise>
  <!-- begin{ProficiencyDrill} -->
  <!--   This drill demonstrates how we can obtain a first degree polynomial -->
  <!--   that approximates <m>f(x_0)</m> near <m>x=0</m>. -->

  <!--   Suppose that  <m>f(x)</m> is some (differentiable) function and that -->
  <!--   <m>l(x) =A+Bx</m>. -->
  <!--   \begin{enumerate}[label={  (\alph*)}] -->
  <!--   \item Show that if <m>f(0)=l(0)</m> then <m>A=f(0).</m> -->
  <!--   \item Show that if <m>f^\prime(0)=l^\prime(0)</m> then -->
  <!--     <m>B=f^\prime(0).</m> -->
  <!--   \end{enumerate} -->
  <!-- \end{ProficiencyDrill} -->
  <p>

    Next, suppose we want to find a second-degree (quadratic)
    polynomial, <m>q(x)</m>, for which <m>f(0)=q(0)</m>, <m>f^\prime(0)=q^\prime(0)</m> and
    <m>f^{\prime\prime}(0)=q^{\prime\prime}(0)</m>.  It is clear that we can
    simply extend what we did in the previous problem. That is, we start
    with a generic second-degree polynomial, <m>q(x) = A+Bx+Cx^2</m>.
  </p>
  <p>

    First we insist that <m>f(0)=q(0)</m>. Evaluating both  functions  at
    <m>x=0</m> gives
    <me>
      f(0) =\eval{A+B x+C x^2}{x}{0} = A+B\cdot 0+C \cdot0^2 =A,
    </me>
    so <m>A=f(0)</m>.
  </p>
  <p>

    To obtain <m>B</m>, differentiate both functions and
    insist that the first two derivatives of <m>f(x)</m> and <m>q(x)</m> match at
    <m>x=0</m>. That is,
    <md>
      <mrow>  f^\prime(0)\amp=\eval{\dfdx{q}{x}}{x}{0}</mrow>
      <mrow>  \amp=\bigeval{B+2Cx}{x}{0}</mrow>
      <mrow>  \amp=B.</mrow>
    </md>
    So <m>f^\prime(0)=B</m>.
  </p>


  <problem>
    <introduction>
      <p>
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Differentiate again and set the second derivatives at <m>x=0</m> equal
          to one another  to show that
          <me>
            C= \frac{f^{\prime\prime}(0)}{2}.
</me>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Show that if the cubic <m>c(x)=A+Bx+Cx^2+Dx^3</m> has the same
      third derivative as <m>f(x)</m> at <m>x=0</m> then
      <me>
        D=\frac{f^{\prime\prime\prime}(0)}{3\cdot2} = \frac{f^{(3)}(0)}{3\cdot2}.
</me>
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Show that if the quartic <m>q(x)=A+Bx+Cx^2+Dx^3+Ex^4</m> has the
      same fourth derivative as <m>f(x)</m> at <m>x=0</m> then
      <me>
        E=\frac{f^{(4)}(0)}{4\cdot 3\cdot2}.
</me>
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem-enumerate} -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Differentiate again and set the second derivatives at <m>x=0</m> equal -->
<!--     to one another  to show that -->
<!--     <me> -->
<!--     C= \frac{f^{\prime\prime}(0)}{2}. -->
<!--     </me> -->
<!--   \item Show that if the cubic <m>c(x)=A+Bx+Cx^2+Dx^3</m> has the same -->
<!--     third derivative as <m>f(x)</m> at <m>x=0</m> then -->
<!--     <me> -->
<!--     D=\frac{f^{\prime\prime\prime}(0)}{3\cdot2} = \frac{f^{(3)}(0)}{3\cdot2}. -->
<!--     </me> -->
<!--   \item Show that if the quartic <m>q(x)=A+Bx+Cx^2+Dx^3+Ex^4</m> has the -->
<!--     same fourth derivative as <m>f(x)</m> at <m>x=0</m> then -->
<!--     <me> -->
<!--     E=\frac{f^{(4)}(0)}{4\cdot 3\cdot2}. -->
<!--     </me> -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem-enumerate} -->

<p>
  It seems clear that we could use this procedure in a
  <q>machine-like</q> way to produce a polynomial approximation of any
  degree.  In fact, this <q>machine</q> for producing approximating
  polynomials was known long before Lagrange, but he made it more
  tractable by replacing differentials, which are very cumbersome to use
  here, with derivatives and his prime notation. In general this
approximating polynomial is called a <term>Taylor Polynomial</term>
named after the English mathematician <url
href="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/"
visual="https://mathshistory.st-andrews.ac.uk/Biographies/Taylor/">Brook
Taylor</url> (<m>1685-1731</m>), but was known to mathematicians
(including Newton and Leibniz) before Taylor.
</p>
<problem>
  <introduction>
    <p>
      This is the process we used to generate our cubic approximation to the
      sine function just before <xref ref="EQSHO5">Equation~\#</xref>.
</p>
</introduction>
<task>
  <statement>
    <p>
      Show that using this process on <m>y=\sin(x)</m> will generate
      the polynomial that we showed you earlier:
      <m>\sin(x)\approx x-\frac{x^3}{6}</m>.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Find the fourth degree Taylor Polynomial approximation for
      <m>f(x)=\sin(x)</m>.
      \comment{You may find this puzzling for a moment or two. Make sure
      you do all the calculations correctly and then believe
      your calculations.}
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Find the fifth degree Taylor Polynomial approximation for
      <m>f(x)=\sin(x)</m> and graph both functions on the same set of axes.
</p>
</statement>
</task>
<task>
  <statement>
    <p>
      Find the sixth degree Taylor Polynomial approximation for
      <m>f(x)=\sin(x)</m>.
</p>
</statement>
</task>
</problem>
<!-- \begin{embeddedproblem} -->
<!--   This is the process we used to generate our cubic approximation to the -->
<!--   sine function just before <xref ref="EQSHO5">Equation~\#</xref>. -->
<!--   \begin{enumerate}[label={  (\alph*)}] -->
<!--   \item Show that using this process on <m>y=\sin(x)</m> will generate -->
<!--     the polynomial that we showed you earlier: -->
<!--     <m>\sin(x)\approx x-\frac{x^3}{6}</m>. -->
<!--   \item Find the fourth degree Taylor Polynomial approximation for -->
<!--     <m>f(x)=\sin(x)</m>.      -->
<!--                 \comment{You may find this puzzling for a moment or two. Make sure -->
<!--       you do all the calculations correctly and then believe -->
<!--         your calculations.} -->
<!--   \item Find the fifth degree Taylor Polynomial approximation for -->
<!--     <m>f(x)=\sin(x)</m> and graph both functions on the same set of axes. -->
<!--   \item Find the sixth degree Taylor Polynomial approximation for -->
<!--     <m>f(x)=\sin(x)</m>. -->
<!--   \end{enumerate} -->
<!-- \end{embeddedproblem} -->

<problem>
  <statement>
    <p>
      Find the second and fourth degree Taylor Polynomial approximations
      for <m>f(x)=\cos(x)</m> and graph them all on the same set of axes.
      Would it make any sense to use the fifth-degree Taylor Polynomial in
      this case?  Explain.
</p>
</statement>
</problem>

<p>
  In general the Taylor Polynomial, of degree <m>n</m>, that approximates a
  differentiable function <m>f(x)</m> is given by:
  <me>
    \label{eq:TaylorFormula}
    T(x)=y(0) +\frac{y^{\prime}(0)}{1!}x
    +\frac{y^{(2)}(0)}{2!}x^2+\frac{y^{(3)}(0)}{3!}x^3
    + \cdots +
    \frac{y^{(n)}(0)}{n!}x^n.
</me>
</p>

<p>
  As you might imagine Taylor Polynomials are incredibly useful
  approximation tools. At this point we have given you only the most
  basic of introductions. You will see this again in much more depth in
  the next course, Integral Calculus.
</p>


</section>
</chapter>

