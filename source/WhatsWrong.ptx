<?xml version='1.0' encoding='utf-8'?>

<chapter xmlns:xi="http://www.w3.org/2001/XInclude"  xml:id="CHAPTERWhatsWrong">
  <title>What's Wrong with Differentials?</title>

  <introduction>
    <title>
      Introduction
    </title>

    <blockquote>
      <p>
        <q>In the pursuit of truth we must beware of being misled
        by terms which we do not rightly understand. That is the chief
        point.</q> 
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/">Bertrand Russell</url> (1872<ndash/>1970)
      </p>
    </blockquote>


    <p>
      To see what<rsq/>s wrong with differentials consider the circle and the
      differential triangle below.
    </p>
    <image source="DC/WrongWithDiff2.png" width="50%">
    </image>

    <p>
      Suppose that <m>\dx{s}</m> is one of the differentials that
      makes up the circle. Since <m>\dx{s}</m> is a non-zero increment
      it has two distinct endpoints so we can draw the two radii
      shown. Because the two (distinct) endpoints that lie on the
      circle are <em>infinitely</em> close together the two lines have
      the same slope. But all of the radii of a circle pass through
      the center of the circle so these two in particular must also
      intersect at the center, and we conclude that we have two
      parallel lines that intersect.
    </p>

    <p>
      But the only way that can happen is if they are actually the
      same line, and if they are the same line then the points on the
      circle are not really distinct as we<rsq/>ve drawn them. But if
      they are not distinct then <m>\dx{x}</m>, <m>\dx{y}</m>, and
      <m>\dx{s}</m> are all actually <em>equal</em> to zero. If
      <m>\dx{x}</m> =0 then <m>\dfdx{y}{x}</m> is meaningless
    (why?).
    </p>

    <p>
      This simple argument appears to completely destroy the differential
      foundation upon which we<rsq/>ve based everything we<rsq/>ve done up until
      now. Try as we might we can<rsq/>t escape the contradictions inherent in
      the very notion of infinitely small numbers.
    </p>

    <p>
    This is very troubling.
    </p>
  </introduction>

  <section  xml:id="CalcAndBerkeley">
    <title>
      Calculus and Bishop Berkeley
    </title>

    <blockquote>
      <p>
        <q>In my opinion, a mathematician, in so far as he is a
        mathematician, need not preoccupy himself with philosophy <mdash/> an
        opinion, moreover, which has been expressed by many
        philosophers.</q> 
      </p>
      <attribution> 
        <url
            href="https://mathshistory.st-andrews.ac.uk/Biographies/Lebesgue/"
            visual="https://mathshistory.st-andrews.ac.uk/Biographies/Lebesgue/">
        Henri Lebesgue </url>
        (1875<ndash/>1941) 
      </attribution>
    </blockquote>

    <figure>
      <caption>
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Berkeley/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Berkeley/">Bishop George Berkeley</url> (1685<ndash/>1753)
      </caption>
      <image source="DC/Berkeley.png" width="25%"/>
    </figure>

    <aside>
      <title>Pronuciation</title>

      <p>His name is properly pronounced <q>bark lee,</q> not
      "burk lee."
      </p>
    </aside>
    <p>
      In <m>1734
      </m> an even more devastating repudiation of differentials was
      published by 
      <url 
          href="https://mathshistory.st-andrews.ac.uk/Biographies/Berkeley" 
          visual="https://mathshistory.st-andrews.ac.uk/Biographies/Berkeley">
        George Berkeley </url>, the Anglican Bishop of the Diocese of
        Cloyne, Ireland in a treatise ponderously entitled,
    </p>
    <aside>
      <title>Comment</title>
      <p>
        Usually it is just called <pubtitle>The Analyst</pubtitle>.
      </p>
    </aside>
    <blockquote>
      <p>
        <url href="https://old.maa.org/press/periodicals/convergence/mathematical-treasure-george-berkeleys-the-analyst" 
             visual="https://.maa.org/press/periodicals/convergence/mathematical-treasure-george-berkeleys-the-analyst">
          <pubtitle>
            THE ANALYST;</pubtitle> or, a Discourse Addressed to an Infidel
            MATHEMATICIAN, wherein it is examined whether the Object,
            Principles, and Inferences of the modern Analysis are more
            distinctly conceived, or more evidently deduced, than Religious
            Mysteries and Points of Faith.
        </url>
      </p>
    </blockquote>
    <p>
      Berkeley<rsq/>s critique was both fierce and correct. Fortunately, it
      was also (mostly) ignored in its time. Just as we have been so far,
      mathematicians of the time were too busy <em>using</em> Calculus to
      concern themselves much with the underlying foundational issues he
      illuminated so well.  But these foundational issues are real and the
      time has come for us to address the profound logical difficulties
      inherent in the notion of an infinitely small quantity.
    </p>
    <p>
      You may well wonder why a Bishop in the Church of England and a
      philosopher would concern himself with the methods of scientific
      analysis and investigation. The fact is that Berkeley didn<rsq/>t really
      have any quarrel with the use of differentials (or fluxions) in
      science at all. He was, in fact, a great admirer of Newton and he
      understood very well that the techniques Newton and Leibniz had
      introduced actually worked, at least most of the time. He says as much
      himself in <pubtitle>The Analyst</pubtitle>
    </p>
    <historical> 
      <title>Historical Note</title>
      <p>
        In the eighteenth century English nouns were frequently
        capitalized, and spelling was not as standardized as it is today,
        so Berkeley<rsq/>s work looks a little odd to modern
        eyes. Nevertheless, it is quite readable. Stretch yourself a bit.
      </p>
    </historical>
    <blockquote>
      <p><q>I have no Controversy about your Conclusions, but only about your
      Logic and Method . .  .  It must be remembered that I am not
      concerned about the truth of your Theorems, but only about the way
      of coming at them; . . . it may perhaps seem an unaccountable
      Paradox, that Mathematicians should deduce true Propositions from
      false Principles, be right in the Conclusion, and yet err in the
      Premises . . . </q>     (Section XX)</p>
    </blockquote>
    <p>
      Berkeley might not have bothered publishing his criticisms of Calculus
      but during the seventeenth and eighteenth centuries a religious
      movement known as <url href="https://www.britannica.com/topic/Deism" visual="https://www.britannica.com/topic/Deism">Deism</url>
      (called
      <q>Free-Thinking</q> in England) was very strong throughout Europe. Many
      of the scientists of the age were supportive of the Deistic movement
      because, while Deism itself is not a form of atheism, many of its
      adherents were atheists. Moreover the Free-Thinkers in England
      explicitly espoused the questioning and criticism of religious tenets
      and attitudes.  Christianity was attacked by some Deists on the
      grounds that it was not logical and contained too many mysteries.
    </p>

    <p>
      As a member of the clergy Berkeley felt compelled to answer these
      criticisms. Speaking directly to the English scientific community he
      said, 
    </p>
    <blockquote>
      <p>    
        <q>Whereas then it is supposed, that you apprehend more
        distinctly, consider more closely, infer more justly, conclude
        more accurately than other Men, and that you are therefore less
        religious because more judicious, I shall claim the privilege of a
        Free-Thinker; and take the Liberty to inquire into the Object,
        Principles, and Method of Demonstration admitted by the
        Mathematicians of the present Age, with the same freedom that you
        presume to treat the Principles and Mysteries of Religion; to the
        end, that all Men may see what right you have to lead, or what
        Encouragement others have to follow you.</q>
        (Section II)
      </p>
    </blockquote>
    <p>
      He made his purpose clear from the outset by including a biblical
      verse (Mathew, chapter 7, verse 5) on the title page of <pubtitle>The
      Analyst</pubtitle>:
    </p>
    <blockquote>
      <p>
        <q>First cast out the beam out of thine own Eye; and then
        shalt thou see clearly to cast out the mote out of thy brother<rsq/>s eye.</q>
      </p>
    </blockquote>

    <p>
      So Berkeley<rsq/>s purpose in writing <pubtitle>The Analyst</pubtitle> was to defend
      his religion rather than to attack mathematics. But he was well
      acquainted with the adage, <q>The best defense is a good offense</q> and
      he mounted a very good defense.
    </p>
    <p>
      Some of Berkeley<rsq/>s specific criticisms will be illuminating.
    </p>
    <aside>
      <title>Historical Background</title>
      <p>
        The language of Calculus wasn<rsq/>t entirely established yet so when
        Berkeley says <q>Differences</q> he means what we<rsq/>ve been calling
    differentials.</p></aside>
    <blockquote>
      <p>     <q> . . .  they consider the Increments or Decrements
      themselves, which they call Differences, and which are supposed to
      be infinitely small  . . . . Now to conceive a Quantity infinitely
      small, that is, infinitely less than any sensible or imaginable
      Quantity, or than any the least finite Magnitude, is, I confess,
      above my Capacity.  . . .  But to conceive a Part of such
      infinitely small Quantity, that shall be still infinitely less
      than it, and consequently though multipliy<rsq/>d infinitely shall
      never equal the minutest finite Quantity is, I suspect, an
      infinite Difficulty to any Man whatsoever . . .</q> (Section V)
      </p>
    </blockquote>


    <p>
      Do you see what he<rsq/>s complaining about? Berkeley is questioning the
      very existence of the differentials we have been relying on
      since we began. And he has a point. As we<rsq/>ve seen our differentials have
      to satisfy two mutually exclusive properties. They can<rsq/>t be zero but
      they must be smaller than <q>the least finite Magnitude.</q> On its face
      this seems to be impossible.
    </p>
    
    <p>
      But Berkeley goes further. He says that:
    </p>
    <blockquote>
      <p> 
        <q> . . .  our modern Analysts are not content to consider
        only the Differences of finite Quantities: they also consider the
        the Differences of those Differences, and the Differences of the
        Differences of the first Differences. And so on <em>ad
        infinitum.</em> That is, they consider Quantities infinitely less
        than the least discernible Quantity; and others infinitely less
        than those infinitely small ones; and still others infinitely less
        than the preceding Infinitesimals, and so on without end or limit
        . . .  And (which is most strange) although you should take a
        Million of Millions of these Infinitesimals, each whereof is
        supposed infinitely greater than some other real Magnitude, and
        add them to the least given Quantity, it shall be never the
        bigger. For this is one of the modest <em>postulata</em> of our
        modern Mathematicians, and it is a Corner-stone or Ground-work of
        their Speculations.</q>    (Section VI)
      </p>
    </blockquote>

    <p>
      Clearly Berkeley is contemptuous of the reasoning we<rsq/>ve used to
      justify our differentiation rules. And, again, he has a point. We have
      pushed aside issues like this until now because we knew we were
      showing you the correct techniques, even if our justifications would
      not bear close examination. In the beginning it was more important
      that you learn to <em>use</em> Calculus than that you understand
      all of the logical subtleties that have been used to justify it
      rigorously.
    </p>
    <p>
      But wait a second. We <em>know</em> Calculus works. We<rsq/>ve been
      successfully solving abstruse and difficult problems with it for some
      time. Throughout the first part of this text we<rsq/>ve seen ample, even
      overwhelming, evidence of this fact.  Isn<rsq/>t that sufficient?  Can<rsq/>t we
      conclude from the fact that it <em>does</em> seem to work that the
      notion of the differential is tenable after all?
    </p>
    <p>
      Sadly, no. Berkeley thought of that too:
    </p>
    <blockquote>
      <p>
        <q>But this inverted way of demonstrating your Principles by your
        Conclusions . . .  is contrary to the Rules of Logic. The truth of
        a Conclusion will not prove either the Form or the Matter . . .
        to be true . . . I say that in every other Science Men prove their
        Conclusions by their Principles, and not their Principles by their
        Conclusions.</q>  (Section XX)
      </p>
    </blockquote>
    <p>
      In order to have confidence in our knowledge, we must begin with
      simple, clear ideas and build on them logically. Nothing else will do.
    </p>

    <p>


      However, the path to simple, clear ideas is neither simple nor
      clear. As we<rsq/>ve mentioned before, it took about two hundred years for
      the mathematical community to find and fully understand how to make
      Calculus rigorous. We introduced the essential idea, the limit,
      intuitively in <xref ref="SECTIONhoriz-asympt-as"></xref>.
    </p>


    <aside>
      <title>Comment</title>
      <p>
        For us
        <q>rigorous</q> means that we can provide an argument that even Bishop
        Berkeley would accept.
      </p>
    </aside>


    <p>

      It would be possible to introduce the limit concept formally  and then
      proceed to develop all of Calculus from it. Logically, there is
      nothing wrong with this approach, and indeed, this is exactly how most
      Calculus books present the topic. But the limit concept is  very
      subtle. Unless you understand exactly what issues it is meant to
      address it is very difficult to understand why it takes the form that
      it does.
    </p>
    <p>

      So, we will continue to build on our intuitive approach. However, our
      focus has changed. In Part I we worked intuitively to build confidence
      in the tools we were building. Here in Part II, our intention is to
      highlight how and where our intuition falls short, so that when we
      finally define the limit concept rigorously in
      <xref ref="DEFINITIONlimits-at-real"></xref> it will be clear why it must
      have the form that it does. What this means is that while our
      intention is to finally  provide the rigor we<rsq/>ve been lacking  we will
      not actually achieve that until the end of
      <xref ref="CHAPTERformal-limits"></xref>
    </p>

  </section>

  <section xml:id="SECTIONsecants-tangents">
    <title>Secants and Tangents</title>

    <blockquote>
      <p>
        Calculus required continuity, and continuity was
        supposed to require the infinitely little; but nobody could discover
        what the infinitely little might be.
      </p>
      <attribution>
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Russell/">Bertrand Russell</url> (1872<ndash/>1970)
      </attribution>
    </blockquote>



    <p>

      In <xref ref="DiffCalcFromPractice"></xref>  we  defined the derivative of <m>y=y(x)</m> to be the differential
      ratio <m>\dfdx{y}{x}</m>, but Berkeley shows in <pubtitle>The Analyst</pubtitle> that there
      are considerable difficulties with this approach. How else might we
      define the derivative? This is our next puzzle.
    </p>
    <p>

      If we want to construct the line tangent at  a particular point, <m>(x_0, y(x_0))</m>
      on a given  curve we immediately have this problem: We only have one
      point, but there are (infinitely) many lines through that point.  A
      few of them are shown below.
</p>
    <image source="DC/LinesThroughPoint.png" width="40%"/>
<p>
      How could we possibly pick the tangent line out of this mess?
    </p>
    <p>

      The only distinguishing feature that the  tangent line has  is that it is in
      fact tangent to our curve. That is not much to go on. But it is not
      nothing either.
    </p>


    <p>

      To form a line we desperately need another point. But where to find
      one? The only other points we have to work with are points on the
      curve itself.
    </p>
    <p>
      <idx><h>Vocabulary</h><h>secant line</h></idx>
      Choose a new point, say <m>(x_1, y(x_1)),</m> on our curve but a
      little to the right of <m>(x_0,y(x_0))</m> and draw the line between
      <m>(x_0,y(x_0))</m> and <m>(x_1,y(x_1))</m> as shown in  the sketch below.
</p>
    <image source="DC/TangentLineCluster4.png" width="40%"/>
<p>
      Recall from <xref ref="CHAPTERcalc-trig"></xref> that the trigonometric secant
      function is so called because it is the length of a line segment which
      cuts the circle. The brown line in this sketch cuts the curve so it is
      called a <term>secant line</term>.
    </p>


    <p>

      Similarly, if we choose a point a little to the left of <m>(x_0,y(x_0))</m>
      and draw another secant line (shown in purple) it should be clear that
      the   tangent line will be between the two
      secant lines in the sketch below.
    </p>
    <image source="DC/TangentLineCluster3.png" width="40%"/>
    <p>

      We have eliminated a lot of potential tangent lines, but we haven<rsq/>t
      eliminated all of them.  Is there a way we could refine our search to
      reduce the set of possible tangent lines even further?
    </p>


    <p>
      Sure. Choose <m>x_3</m> between <m>x_0</m> and <m>x_1</m> and draw the (blue) secant
      line from <m>x_0</m> to <m>x_3,</m> and then choose <m>x_4</m> between <m>x_0</m> and
      <m>x_2</m> and draw the (green) secant line through them to get the sketch
      below.
</p>
    <image source="DC/TangentLineCluster.png" width="40%"/>
<p>
  It is clear that we have eliminated more potential
      tangent lines, and that by continuing to choose points even closer to
      <m>x_0</m> we can eliminate even more of them.
    </p>
    <p>
      This approach seems to have some potential but there are at least two
      difficulties:

      <ol>
        <li>
          <p>
            So far we<rsq/>ve relied heavily on diagrams to motivate our
            approach, and we know that diagrams can be misleading. 
            However this is not as serious as it seems to be because we are only
            using the diagrams to motivate a new definition for the
            derivative. Once that definition is in place we can disregard the
            diagrams and work directly with the definition
            regardless of the shape of the graph.
          </p>
          <p>
            You should generate a few graphs of your own, different from ours
            and from each other, to confirm that our arguments work for them as
            well.
          </p>
        </li>
        <li>
          <p>
            We<rsq/>ve been drawing the tangent lines but we need to keep in mind
            that the line tangent to the graph of our function at a point is not
            the derivative of the function.  The derivative is the slope of the
            tangent line. And slope is a number. The pictures we<rsq/>ve drawn so far
            are very suggestive but they don<rsq/>t give us numbers.
          </p>
        </li>
      </ol>

    </p>


    <p>
      For the time being, we will handle the first difficulty by ignoring
      it. That is, we will continue to use diagrams to motivate our ideas,
      but when we are done we will have to circle back and ask ourselves if our
      reliance on those diagrams has caused us to miss any special cases
      which need to be addressed.
    </p>
    <p>
      To handle the second difficulty consider the sketch below.
</p>
    <image source="DC/TangentLineCluster2.png" width="40%"/>
<p>

      It is clear that if the tangent line, <m>T</m>, is
      caught between lines secant lines <m>S_1</m> and <m>S_2</m>, then the <em>slope</em> of <m>T</m> is
      necessarily caught between the <em>slope</em> of <m>S_1</m> and the
      <em>slope</em> of <m>S_2.</m> Thus we have
      <me>
        \text{slope of } S_1=\frac{y(x_1)-y(x_0)}{x_1-x_0}\gt \text{slope of }T\gt
        \frac{y(x_2)-y(x_0)}{x_2-x_0}=\text{slope of } S_2.
      </me>
      A specific example will be helpful.
    </p>

    <example xml:id="EXAMPLEyEQxR2-limits">

      
      <p>

        Suppose <m>y=x^2</m>. We would like to compute the derivative (slope of
        the line tangent to the graph) of <m>y</m> at the point <m>x=2</m> by the the
        procedure indicated above.
      </p>
      <p>

        Before we start, observe that from our work with differentials we
        know what we are expecting to get. It is
        <me>y^\prime(2)=\left.\dfdx{y}{x}\right|_{x=2}=\bigeval{2x}{x}{2}=2\cdot2=4.</me>
      </p>
      <p>

        Taking <m>x_1=2.1</m> and <m>x_2=1.9,</m> gives
        <md>
          <mrow>

            \frac{y(2.1)-y(2)}{2.1-2}\amp{}\gt y^\prime(2)\gt\frac{y(1.9)-y(2)}{1.9-2} \\
          </mrow>
          <mrow>

            \frac{(2.1)^2-(2)^2}{.1}\amp{}\gt  y^\prime(2)\gt\frac{(1.9)^2-y(2)}{.9}
          </mrow>
          <mrow>
            4.1\amp{}\gt y^\prime(2)\gt3.9.
          </mrow>
        </md>

      </p>
      <p>
        <idx><h>Vocabulary</h><h>bounded</h></idx>
        <idx><h>Vocabulary</h><h>bound</h></idx>
        So our proposed procedure seems to be heading us in the right
        direction. If we take <m>x_3=2.01</m> and <m>x_4=1.99</m> we get
        <me>
          4.01\gt y^\prime(2)\gt3.99.
        </me>
        We say that <m>y^\prime(2)</m> is <term>bounded</term>, and that the numbers
        <m>4.01</m> and <m>3.99</m> are the <term>bounds</term>.
      </p>

    </example>
    <exercise xml:id="PROBLEMBounds">
      <introduction>
        <p>
          
          Compute bounds on the derivatives of each function given at <m>x=2</m> by
          using the values of <m>x_1</m> and <m>x_2</m> given below.
          <ol cols="2" marker="(i)">
            <li>
              <p>
                <m>x_1=2.001,</m> <m>x_2=1.999</m>
              </p>
            </li>
            <li>
              <p>
                <m>x_1=2.0001,</m> <m>x_2=1.9999</m>
              </p>
            </li>
            <li>
              <p>
                <m>x_1=2.00001,</m> <m>x_2=1.99999</m>
              </p>
            </li>
            <li>
              <p>
                <m>x_{1}=2.000001,</m> <m>x_{2}=1.999999</m>
              </p>
            </li>
          </ol>
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            <m>y=x^2</m>, 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>y=x^3</m>, 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>y=-\frac{1}{x}</m>,  and 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>y=x^{1/2}</m>
          </p>
        </statement>
      </task>
</exercise>

    <p>
      The results in <xref ref="PROBLEMBounds"></xref> are looking very
      promising indeed. Since they are looking so promising we<rsq/>ll take a few
      minutes to simplify our notation a bit.
    </p>

    <p>
      It is tedious to have all of these subscripted <m>x</m> variables
      (<m>x_0, x_1, x_2, \cdots</m>) so we will define an equivalent, but more
      useful, notation. The basic idea here is that we move to a new point
      a little bit away from <m>x_0</m> and form the quotient that gives the
      slope of the secant line at that point. To construct the first
      secant line we took <m>x_1</m> to be a number a little to the right of
      <m>x_0</m>. However, if we take <m>h</m> to be a positive number near zero
      then <m>x_0+h</m> expresses the same idea.  Similarly, to construct a
      secant line a little to the left of <m>x_0</m> we take <m>h</m> to be a
      negative number near zero so that <m>x_0+h</m> expresses the same idea.
    </p>

    <image source="DC/Secant-h.png" width="60%"/>

    <p>

      We can capture both situations notationally by agreeing that <m>h</m> is a
      number (either positive or negative) which is close to zero. Thus
      when <m>h</m> is positive the
      point <m>x_0+h</m> is to the right, and when <m>h</m> is negative the point
      <m>x_0+h</m> is to the left of <m>x_0</m> as shown in the diagram at the right.
    </p>
    <p>
      <idx><h>Principle of Local Linearity</h></idx>

      When we express the idea this way we no longer need to generate all of
      the independent variables, <m>x_1, x_2, x_3, \ldots</m>. We can accomplish
      the same thing by taking <m>x_h=x_0+h,</m> where <m>h</m> is some arbitrary real
      number, which is close to zero. 
      Each
      value of <m>h</m> gives us a different secant line through the point
      <m>(x_0,y(x_0)),</m> and its slope will be

      <men  xml:id="EQUATIONDefDeriv">
        \frac{y(x_0+h)-y(x_0)}{(x_0+h)-x_0}
        =\frac{y(x_0+h)-y(x_0)}{h}

      </men>

      By the <xref ref="DEFINITIONLocalLinearity">Principle of Local Linearity</xref>  we see that when <m>h</m> is very small
      the quotient <m>\frac{y(x_0+h)-y(x_0)}{h}</m> will be very close to the the
      slope of the tangent line.
    </p>
    <p>

      There is also a small technical matter we need to think about: Do we
      really need to consider secant lines on either side of <m>x_0</m> (for both
      positive and negative values of <m>h</m>)? Would it not be sufficient to
      consider just the secant lines on the right formed from the sequence
      <m>x_1=2.1, x_1=2.01, x_1=2.001,\ \ldots?</m> It seems pretty clear that
      the slopes we get, <m>4.1, 4.01, 4.001, \ldots</m> are getting closer to
      <m>4</m>. Isn<rsq/>t that enough?
    </p>
    <p>

      No, it is not. But not because there is any inherent logical flaw in
      doing so. This has more to do with the properties we want the
      derivative to have than any purely logical consideration, so we<rsq/>ll
      hold off  further discussion until
      <xref ref="SECTIONfirst-deriv-test"></xref>.
    </p>

    <image source="DC/EpsSlope2.png" width="40%"/>

    <p>
      Returning to the example  <m>y=x^2</m> at <m>x=2</m>,
      we let <m>h</m> be any number except zero and find of the secant line
      through <m>(2,4)</m> and <m>(2+h,(2+h)^2)</m>. We can<rsq/>t let <m>h</m> be zero because
      if it is zero
      then <m>(2,4)</m> and <m>(2+h,(2+h)^2)</m> are the same point and
      we can<rsq/>t construct the secant line. We 
      <em>must</em> have <m>h\neq0</m> just to
      get started. In that case we have

      <mdn>
        <mrow number="no">
          \frac{y(2+h)-y(2)}{h} =   \frac{(2+h)^2-2}{h}  \amp= \frac{4+4h+h^2-4}{h}
        </mrow>
        <mrow number="no">\amp=\frac{4h+h^2}{h}</mrow>
        <mrow  xml:id="EQUATIONsqrslope1">\amp= 4+h.</mrow>
      </mdn>

    </p>
    <p>
      This is interesting. Do you recognize this computation? It should be
      familiar to you. This is precisely the same computation you did when
      you used Fermat<rsq/>s adaptation of the Method of Adequality to find
      tangent lines in <xref ref="PROBLEMFermMethX2"></xref>. The only
      difference, really, is that at this point Fermat would simply set
      <m>h=0</m> and move on.  We can<rsq/>t do that because we need two
      distinct points to specify a (secant) line. If <m>h=0</m> we only have
      one. This is frustrating because we can see that setting <m>h=0</m>
      will give us <m>y^\prime(2)=4</m> which we know to be the correct
      value.
    </p>
    <p>
      Berkeley pointed out the problem of setting <m>h=0</m> in <pubtitle>The
      Analyst</pubtitle> (his Increments are what we<rsq/>ve called <m>h</m>):
    </p>
    <blockquote>
      <p>    
        .  .  . this reasoning is not fair or conclusive. For
        when it is said, let the Increments vanish, i.e. let the
        Increments be nothing, or let there be no Increments, the former
        Supposition that the Increments were something, or that there were
        Increments is destroyed, and yet as a Consequence of that
        Supposition, i.e. an Expression got by virtue thereof, is
        retained. Which  .  .  . is a false way of reasoning. Certainly
        when we suppose the Increments to vanish, we must suppose their
        Proportions, their Expressions, and every thing else derived from
        the Supposition of their Existence to vanish with them.
      </p>
    </blockquote>


    <p>
      Requiring <m>h</m> to be non-zero at the beginning of our argument, and
      zero at the end is tantamount to requiring <m>h</m> to be zero and not zero
      simultaneously which is not possible.  So <m>h</m> can<rsq/>t be zero. But it
      can be very close to zero. Moreover as it gets closer to zero
      (<m>h\rightarrow0</m>) it is clear that <m>4+h\rightarrow4</m>.

      This should also feel very familiar to you. Do you see that we<rsq/>re
      talking about a limit? From <xref ref="EQUATIONsqrslope1">equation</xref> we see that
      as  <m>h\rightarrow0</m>, 
      <me>
        \frac{y(2+h)-y(2)}{h} =  4+h \rightarrow4.
      </me>
      Moreover, by the Principle of Local Linearity as <m>h\rightarrow0</m> the
      secant and tangent lines become indistinguishable.
      Thus it appears that  the limit
      <me>
        \limit{h}{0}{\frac{y(2+h)-y(2)}{h}} =
        \limit{h}{0}{\frac{4+4h+h^2-4}{h}} = \limit{h}{0}{4+h}= 4
      </me>
      will be the value of the derivative at <m>x=2</m>.
    </p>


    <p>

      Our discussion in <xref ref="EXAMPLEyEQxR2-limits"></xref> suggests that we can
      use the limit concept to finally resolve the logical difficulties
      inherent in a naive use of the differential as a foundation for Calculus,
      and that is exactly our present goal.
    </p>

    <aside>
      <title>Historical Background</title>

      <p>
        We say <q>naive</q> because the fact is that
        the differential concept actually can be made fully rigorous and
        thus can serve as a foundation for Calculus just as well as the
        limit theory we are currently pursuing.  Such a foundation was built
        by the
        mathematician
        <url href="https://mathshistory.st-andrews.ac.uk/Biographies/Robinson/" visual="https://mathshistory.st-andrews.ac.uk/Biographies/Robinson/">Abraham
        Robinson</url> (1918<ndash/>1974) is his 1966 book <pubtitle>Non-Standard
        Analysis</pubtitle>. However Robinson used ideas and techniques from modern
        mathematical logic which were not available to mathematicians of the
        seventeenth century. Because they are they are not available to us
        either, we will justify our methods using the older, slightly simpler,
        limit theory.
      </p>
    </aside>



    <p>

      In this second part
      of this text we will finally build a viable theory  to support
      Calculus which even Bishop Berkeley would have to accept. We begin
      with the following definition. This is the modern definition of the
      derivative.
    </p>



    <definition xml:id="DEFINITIONDerivative">
      <title>The Derivative</title>
      <idx><h>Definition</h><h>The Derivative</h></idx>
      <statement>
        <p>
          <idx><h>Vocabulary</h><h>differentiable</h></idx> 
          Suppose <m>f</m> is a function, and that <m>x</m> is a real number. If
          <m>\limit{h}{0}{\frac{f(x+h{})-f(x)}{h}}</m> exists then we say that <m>f</m>
          is <term>differentiable</term> at <m>x</m> and that the derivative of <m>f</m> at
          <m>x</m> is given by:

          <men  xml:id="EQUATIONDefDerivative">
            f^\prime(x)=\dfdx{f}{x}=\limit{h}{0}{\frac{f(x+h{})-f(x)}{h}}
          </men>

          if this limit exists. If the limit does not exist then the
          derivative also  does not exist at <m>x</m>.

        </p>
      </statement>
    </definition>

    <p>
      <xref ref="DEFINITIONDerivative"></xref> defines the derivative locally, <q>at
      <m>x</m>.</q> This may seem to be a mere formality but it is not. When we
      write <m>f(x)</m> it is easy to fall into the habit of thinking of <m>x</m> as
      representing all of the points in the domain of <m>f</m>.  But that is
      fundamentally wrong. The variable <m>x</m> always represents a single point
      in the domain of <m>f</m>. Always. No exceptions.  When its value is
      unknown we call it  <m>x</m> (or <m>y</m>, or <m>z</m>, or Fred, Ethel, Ricky,
      or Lucy. These are all just names we give to a  unknown specific quantity) because this is simpler than saying <q>whatever
      point we<rsq/>re interested in.</q>  This is why the symbol <m>f(x)</m> is
      pronounced <q><m>f</m> of <m>x</m>,</q> or <q><m>f</m> at <m>x</m>.</q>
    </p>

    <p>

      In  <xref ref="EXAMPLEyEQxR2-limits"></xref> we evaluated the
      derivative of <m>f(x)=x^2</m> at the single point <m>x=2</m>.  It appears that
      if we want to evaluate the derivative of <m>f(x)=x^2</m> at <m>x=3</m> and <m>x=4</m>
      we need to compute <m> \tlimit{h}{0}{\frac{f(3+h)-f(3)}{h}}</m>, and
      <m> \tlimit{h}{0}{\frac{f(4+h)-f(4)}{h}}</m>.
    </p>
    <p>

      But it is tedious to compute the derivative of a function one specific
      point at a time. If we leave <m>x</m> unspecified and compute
      <m> f^\prime(x)=\limit{h}{0}{\frac{f(x+h)-f(x)}{h}} </m> we obtain the
      value of the derivative of <m>f</m> at the single, but unspecified point
      <m>x</m>. We can then find the
      derivative of <m>f</m> at any point by replacing <m>x</m> with whatever point we are
      interested in.
    </p>
    <p>

    </p>
    
    <exercise xml:id="PROBLEMxIsSingular">
      <introduction>
        <p>
          
          Use the techniques we saw in <xref
          ref="CHAPTERlimits-lhop-rule"></xref> to compute <m>f^\prime(x)</m>
          by evaluating a limit. Check your work by differentiating using
          differentials.  
        </p>
        <p>
          Do not use L<rsq/>Hôpital<rsq/>s Rule. L<rsq/>Hôpital<rsq/>s Rule as
          that would be circular reasoning.
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            <m>f(x)=x^2</m> 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=2x^2-x</m> 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=x^6-7x^4</m> 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=\pi</m> 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=\frac{1}{x^3}</m> 
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=-\frac{1}{x}</m>
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=x^{1/2}</m>
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>f(x)=x^{1/3}</m> 
          </p>
        </statement>
      </task>
</exercise>
    
    <p>
      <idx><h>Vocabulary</h><h>differentiable</h></idx>
      When a function is
      differentiable at all  of the points in its domain it is said to be
      <term>differentiable on its domain</term> or just <term>differentiable</term>.
    </p>

    <aside>
      <title>Comment</title>
      <p>
        <idx><h>Vocabulary</h><h>differentiable</h></idx>
        In practice we are often quite loose with
        the term <term>differentiable</term>. Most people would call the functions 
        <m>f(x)=\sqrt{x}</m> and <m>g(x)=\sqrt[3]{x}</m> <term>differentiable</term> even
        though they both fail to be differentiable at <m>x=0</m>.
      </p>
    </aside>

    <exercise>
      <statement>
        <p>
          <idx><h>Vocabulary</h><h>differentiable</h></idx>
          Which of the functions in <xref ref="PROBLEMxIsSingular"></xref> are
          <term>differentiable</term> and which are not? Identify all points of
          non-differentiability.
        </p>
      </statement>
    </exercise>
    <aside>
      <title>Comment </title>
      <p>
        Newton<rsq/>s
        fluxions are nowhere to be seen, however.
      </p>
    </aside>

    <p>
      If you look closely at <xref ref="DEFINITIONDerivative"></xref> you can see
      Leibniz<rsq/> differentials lurking in the background. If we let
      <m>\Delta{}y=f(x+h{})-f(x)</m> and <m>\Delta x = h</m> then for values of <m>h</m>
      very close to zero we have.
      <me>
        f^\prime(x) \approx \frac{\Delta y}{\Delta x} =
        \frac{f(x+h{})-f(x)}{h}.
      </me>
      The approximation gets better as <m>\Delta x\rightarrow0</m>
      (equivalently, as <m>h\rightarrow0</m>) so you can see that
      <xref ref="DEFINITIONDerivative"></xref> avoids the infinitely small by
      replacing differentials with <m>\Delta x</m> (equivalently <m>h</m>) which is
      a small, but finite, number which is only considered in the limit as
      <m>\Delta x\rightarrow0</m>. In particular, <m>\Delta x</m> is not an
      infinitesimal. But it is allowed to become as close to zero as
      needed while remaining finite in size.  Needless to say, limits are
      much harder to work with than differentials. Their saving grace is
      if they can be made logically unassailable with a proper
      definition. Bishop Berkeley would approve.
    </p>
    <p>

      For the rest of this text we pursue two over-arching goals.  The
      first is to rigorously recapture from
      <xref ref="DEFINITIONDerivative"></xref> all of the differentiation rules
      we are already familiar with.  We will address that in the first
      section of the next chapter. Keep in mind that we are not developing
      the differentiation rules. We already know them, and by now you
      should be quite skillful at their use. Our goal now is to show
      rigorously that by using <xref ref="DEFINITIONDerivative"></xref> we
      can recapture all of the properties that we found so useful before.
    </p>
    <p>

      To do this we will need several properties of limits which we will
      state <mdash/> without proof <mdash/> in the next section. Then we will prove
      that our differentiation rules and the First Derivative Test are
      valid using <xref ref="DEFINITIONDerivative"></xref>. However all of this
      will be done under the assumption that the limit properties in the
      next section are actually true.
    </p>
    <p>

      Our second goal is to prove, rigorously that the limit properties in
      the next section are actually true. We will do this in
      <xref ref="SECTIONLimitLaws"></xref>.
    </p>
  </section>

</chapter>

